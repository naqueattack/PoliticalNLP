{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67233b73-f1a2-4cab-a395-0acf30fb4ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Andrew\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Andrew\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "df = pd.read_csv(\"../data/fulldata.csv\")\n",
    "df2 = pd.read_csv(\"../data/6_14_pull.csv\")\n",
    "\n",
    "df = pd.concat([df,df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a16c2532-c2f2-48f7-84f6-7f9e0049ea0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Cleaning import lowercase, unpunctuate, tokenize, lemmatize, count_capitalized_words, create_other_var, cleaning_and_prep, stack_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb47f54a-ec57-4308-a10d-62853364b7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andrew\\Documents\\LHL\\PoliticalNLP\\python\\Cleaning.py:127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Political Lean'] = df['Political Lean'].replace('Liberal',1)\n",
      "C:\\Users\\Andrew\\Documents\\LHL\\PoliticalNLP\\python\\Cleaning.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Political Lean'] = df['Political Lean'].replace('Conservative',0)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = cleaning_and_prep(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c07ff43-bee3-4c11-9e29-29c25764a85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vec, X_test_vec, X_train, X_test = stack_vectors(X_train,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83645586-d576-4de0-ae1e-d3897c0b206b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "763/763 [==============================] - 8s 8ms/step - loss: 0.6063 - accuracy: 0.6637 - auc: 0.7337 - val_loss: 0.5819 - val_accuracy: 0.6826 - val_auc: 0.7722\n",
      "Epoch 2/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.5665 - accuracy: 0.6948 - auc: 0.7751 - val_loss: 0.5668 - val_accuracy: 0.6940 - val_auc: 0.7825\n",
      "Epoch 3/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.5544 - accuracy: 0.7066 - auc: 0.7860 - val_loss: 0.5563 - val_accuracy: 0.7119 - val_auc: 0.7929\n",
      "Epoch 4/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.5456 - accuracy: 0.7119 - auc: 0.7933 - val_loss: 0.5561 - val_accuracy: 0.7153 - val_auc: 0.7907\n",
      "Epoch 5/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.5391 - accuracy: 0.7174 - auc: 0.8004 - val_loss: 0.5490 - val_accuracy: 0.7130 - val_auc: 0.7971\n",
      "Epoch 6/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.5346 - accuracy: 0.7226 - auc: 0.8035 - val_loss: 0.5567 - val_accuracy: 0.7044 - val_auc: 0.8029\n",
      "Epoch 7/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.5295 - accuracy: 0.7257 - auc: 0.8086 - val_loss: 0.5423 - val_accuracy: 0.7228 - val_auc: 0.8035\n",
      "Epoch 8/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.5238 - accuracy: 0.7321 - auc: 0.8127 - val_loss: 0.5332 - val_accuracy: 0.7205 - val_auc: 0.8062\n",
      "Epoch 9/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.5195 - accuracy: 0.7331 - auc: 0.8161 - val_loss: 0.5418 - val_accuracy: 0.7214 - val_auc: 0.8062\n",
      "Epoch 10/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.5153 - accuracy: 0.7360 - auc: 0.8204 - val_loss: 0.5293 - val_accuracy: 0.7274 - val_auc: 0.8122\n",
      "Epoch 11/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.5111 - accuracy: 0.7409 - auc: 0.8236 - val_loss: 0.5234 - val_accuracy: 0.7328 - val_auc: 0.8158\n",
      "Epoch 12/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.5059 - accuracy: 0.7415 - auc: 0.8267 - val_loss: 0.5326 - val_accuracy: 0.7218 - val_auc: 0.8162\n",
      "Epoch 13/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.5014 - accuracy: 0.7460 - auc: 0.8303 - val_loss: 0.5232 - val_accuracy: 0.7318 - val_auc: 0.8165\n",
      "Epoch 14/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.4958 - accuracy: 0.7466 - auc: 0.8347 - val_loss: 0.5224 - val_accuracy: 0.7351 - val_auc: 0.8180\n",
      "Epoch 15/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.4956 - accuracy: 0.7479 - auc: 0.8360 - val_loss: 0.5207 - val_accuracy: 0.7328 - val_auc: 0.8181\n",
      "Epoch 16/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.4887 - accuracy: 0.7551 - auc: 0.8408 - val_loss: 0.5103 - val_accuracy: 0.7411 - val_auc: 0.8268\n",
      "Epoch 17/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.4871 - accuracy: 0.7503 - auc: 0.8408 - val_loss: 0.5247 - val_accuracy: 0.7397 - val_auc: 0.8234\n",
      "Epoch 18/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.4807 - accuracy: 0.7587 - auc: 0.8462 - val_loss: 0.5179 - val_accuracy: 0.7400 - val_auc: 0.8294\n",
      "Epoch 19/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.4775 - accuracy: 0.7616 - auc: 0.8487 - val_loss: 0.5313 - val_accuracy: 0.7328 - val_auc: 0.8283\n",
      "Epoch 20/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.4742 - accuracy: 0.7664 - auc: 0.8506 - val_loss: 0.5193 - val_accuracy: 0.7462 - val_auc: 0.8290\n",
      "Epoch 21/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.4693 - accuracy: 0.7651 - auc: 0.8535 - val_loss: 0.5048 - val_accuracy: 0.7467 - val_auc: 0.8358\n",
      "Epoch 22/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.4635 - accuracy: 0.7677 - auc: 0.8578 - val_loss: 0.5167 - val_accuracy: 0.7430 - val_auc: 0.8318\n",
      "Epoch 23/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.4601 - accuracy: 0.7707 - auc: 0.8607 - val_loss: 0.5021 - val_accuracy: 0.7523 - val_auc: 0.8388\n",
      "Epoch 24/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.4584 - accuracy: 0.7760 - auc: 0.8614 - val_loss: 0.5079 - val_accuracy: 0.7525 - val_auc: 0.8341\n",
      "Epoch 25/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.4528 - accuracy: 0.7760 - auc: 0.8651 - val_loss: 0.5121 - val_accuracy: 0.7418 - val_auc: 0.8369\n",
      "Epoch 26/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.4484 - accuracy: 0.7803 - auc: 0.8682 - val_loss: 0.5129 - val_accuracy: 0.7479 - val_auc: 0.8376\n",
      "Epoch 27/100\n",
      "763/763 [==============================] - 6s 8ms/step - loss: 0.4444 - accuracy: 0.7796 - auc: 0.8714 - val_loss: 0.5018 - val_accuracy: 0.7592 - val_auc: 0.8421\n",
      "Epoch 28/100\n",
      "763/763 [==============================] - 6s 8ms/step - loss: 0.4398 - accuracy: 0.7842 - auc: 0.8735 - val_loss: 0.5095 - val_accuracy: 0.7527 - val_auc: 0.8392\n",
      "Epoch 29/100\n",
      "763/763 [==============================] - 7s 9ms/step - loss: 0.4341 - accuracy: 0.7883 - auc: 0.8774 - val_loss: 0.5082 - val_accuracy: 0.7590 - val_auc: 0.8452\n",
      "Epoch 30/100\n",
      "763/763 [==============================] - 7s 9ms/step - loss: 0.4289 - accuracy: 0.7898 - auc: 0.8806 - val_loss: 0.5071 - val_accuracy: 0.7616 - val_auc: 0.8433\n",
      "Epoch 31/100\n",
      "763/763 [==============================] - 7s 9ms/step - loss: 0.4256 - accuracy: 0.7930 - auc: 0.8824 - val_loss: 0.5022 - val_accuracy: 0.7574 - val_auc: 0.8479\n",
      "Epoch 32/100\n",
      "763/763 [==============================] - 6s 8ms/step - loss: 0.4203 - accuracy: 0.7961 - auc: 0.8863 - val_loss: 0.5094 - val_accuracy: 0.7564 - val_auc: 0.8482\n",
      "Epoch 33/100\n",
      "763/763 [==============================] - 7s 9ms/step - loss: 0.4160 - accuracy: 0.8004 - auc: 0.8881 - val_loss: 0.5209 - val_accuracy: 0.7632 - val_auc: 0.8509\n",
      "Epoch 34/100\n",
      "763/763 [==============================] - 6s 7ms/step - loss: 0.4132 - accuracy: 0.7999 - auc: 0.8904 - val_loss: 0.4925 - val_accuracy: 0.7706 - val_auc: 0.8530\n",
      "Epoch 35/100\n",
      "763/763 [==============================] - 6s 7ms/step - loss: 0.4053 - accuracy: 0.8045 - auc: 0.8942 - val_loss: 0.5109 - val_accuracy: 0.7632 - val_auc: 0.8502\n",
      "Epoch 36/100\n",
      "763/763 [==============================] - 6s 8ms/step - loss: 0.4038 - accuracy: 0.8071 - auc: 0.8955 - val_loss: 0.5080 - val_accuracy: 0.7678 - val_auc: 0.8552\n",
      "Epoch 37/100\n",
      "763/763 [==============================] - 6s 8ms/step - loss: 0.3955 - accuracy: 0.8107 - auc: 0.8997 - val_loss: 0.5161 - val_accuracy: 0.7694 - val_auc: 0.8532\n",
      "Epoch 38/100\n",
      "763/763 [==============================] - 7s 9ms/step - loss: 0.3951 - accuracy: 0.8135 - auc: 0.9011 - val_loss: 0.5034 - val_accuracy: 0.7588 - val_auc: 0.8511\n",
      "Epoch 39/100\n",
      "763/763 [==============================] - 6s 7ms/step - loss: 0.3897 - accuracy: 0.8157 - auc: 0.9038 - val_loss: 0.5000 - val_accuracy: 0.7715 - val_auc: 0.8561\n",
      "Epoch 40/100\n",
      "763/763 [==============================] - 6s 7ms/step - loss: 0.3856 - accuracy: 0.8188 - auc: 0.9057 - val_loss: 0.4929 - val_accuracy: 0.7690 - val_auc: 0.8581\n",
      "Epoch 41/100\n",
      "763/763 [==============================] - 6s 8ms/step - loss: 0.3814 - accuracy: 0.8223 - auc: 0.9077 - val_loss: 0.4952 - val_accuracy: 0.7746 - val_auc: 0.8618\n",
      "Epoch 42/100\n",
      "763/763 [==============================] - 6s 8ms/step - loss: 0.3744 - accuracy: 0.8239 - auc: 0.9107 - val_loss: 0.5004 - val_accuracy: 0.7683 - val_auc: 0.8562\n",
      "Epoch 43/100\n",
      "763/763 [==============================] - 6s 7ms/step - loss: 0.3675 - accuracy: 0.8279 - auc: 0.9144 - val_loss: 0.4961 - val_accuracy: 0.7736 - val_auc: 0.8649\n",
      "Epoch 44/100\n",
      "763/763 [==============================] - 6s 8ms/step - loss: 0.3632 - accuracy: 0.8300 - auc: 0.9164 - val_loss: 0.4934 - val_accuracy: 0.7804 - val_auc: 0.8657\n",
      "Epoch 45/100\n",
      "763/763 [==============================] - 6s 8ms/step - loss: 0.3574 - accuracy: 0.8345 - auc: 0.9194 - val_loss: 0.5062 - val_accuracy: 0.7785 - val_auc: 0.8622\n",
      "Epoch 46/100\n",
      "763/763 [==============================] - 6s 8ms/step - loss: 0.3579 - accuracy: 0.8304 - auc: 0.9192 - val_loss: 0.5157 - val_accuracy: 0.7822 - val_auc: 0.8615\n",
      "Epoch 47/100\n",
      "763/763 [==============================] - 6s 8ms/step - loss: 0.3507 - accuracy: 0.8347 - auc: 0.9226 - val_loss: 0.4992 - val_accuracy: 0.7827 - val_auc: 0.8696\n",
      "Epoch 48/100\n",
      "763/763 [==============================] - 6s 8ms/step - loss: 0.3509 - accuracy: 0.8383 - auc: 0.9224 - val_loss: 0.5036 - val_accuracy: 0.7813 - val_auc: 0.8690\n",
      "Epoch 49/100\n",
      "763/763 [==============================] - 6s 8ms/step - loss: 0.3395 - accuracy: 0.8442 - auc: 0.9275 - val_loss: 0.5039 - val_accuracy: 0.7862 - val_auc: 0.8681\n",
      "Epoch 50/100\n",
      "763/763 [==============================] - 6s 7ms/step - loss: 0.3394 - accuracy: 0.8442 - auc: 0.9278 - val_loss: 0.4971 - val_accuracy: 0.7815 - val_auc: 0.8701\n",
      "Epoch 51/100\n",
      "763/763 [==============================] - 6s 8ms/step - loss: 0.3333 - accuracy: 0.8494 - auc: 0.9311 - val_loss: 0.4969 - val_accuracy: 0.7910 - val_auc: 0.8744\n",
      "Epoch 52/100\n",
      "763/763 [==============================] - 7s 9ms/step - loss: 0.3279 - accuracy: 0.8513 - auc: 0.9330 - val_loss: 0.5062 - val_accuracy: 0.7813 - val_auc: 0.8690\n",
      "Epoch 53/100\n",
      "763/763 [==============================] - 7s 9ms/step - loss: 0.3217 - accuracy: 0.8541 - auc: 0.9355 - val_loss: 0.5084 - val_accuracy: 0.7910 - val_auc: 0.8741\n",
      "Epoch 54/100\n",
      "763/763 [==============================] - 8s 10ms/step - loss: 0.3199 - accuracy: 0.8565 - auc: 0.9364 - val_loss: 0.5096 - val_accuracy: 0.7889 - val_auc: 0.8725\n",
      "Epoch 55/100\n",
      "763/763 [==============================] - 9s 11ms/step - loss: 0.3178 - accuracy: 0.8569 - auc: 0.9383 - val_loss: 0.4898 - val_accuracy: 0.7927 - val_auc: 0.8777\n",
      "Epoch 56/100\n",
      "763/763 [==============================] - 7s 9ms/step - loss: 0.3110 - accuracy: 0.8598 - auc: 0.9399 - val_loss: 0.5068 - val_accuracy: 0.7910 - val_auc: 0.8729\n",
      "Epoch 57/100\n",
      "763/763 [==============================] - 7s 9ms/step - loss: 0.3104 - accuracy: 0.8595 - auc: 0.9407 - val_loss: 0.5039 - val_accuracy: 0.7992 - val_auc: 0.8813\n",
      "Epoch 58/100\n",
      "763/763 [==============================] - 7s 10ms/step - loss: 0.3017 - accuracy: 0.8639 - auc: 0.9436 - val_loss: 0.4986 - val_accuracy: 0.8015 - val_auc: 0.8802\n",
      "Epoch 59/100\n",
      "763/763 [==============================] - 7s 10ms/step - loss: 0.2996 - accuracy: 0.8638 - auc: 0.9441 - val_loss: 0.5370 - val_accuracy: 0.7883 - val_auc: 0.8715\n",
      "Epoch 60/100\n",
      "763/763 [==============================] - 7s 9ms/step - loss: 0.2982 - accuracy: 0.8677 - auc: 0.9449 - val_loss: 0.5219 - val_accuracy: 0.8024 - val_auc: 0.8822\n",
      "Epoch 61/100\n",
      "763/763 [==============================] - 7s 9ms/step - loss: 0.2929 - accuracy: 0.8684 - auc: 0.9471 - val_loss: 0.5099 - val_accuracy: 0.7992 - val_auc: 0.8831\n",
      "Epoch 62/100\n",
      "763/763 [==============================] - 7s 9ms/step - loss: 0.2858 - accuracy: 0.8715 - auc: 0.9496 - val_loss: 0.5149 - val_accuracy: 0.8001 - val_auc: 0.8822\n",
      "Epoch 63/100\n",
      "763/763 [==============================] - 6s 8ms/step - loss: 0.2856 - accuracy: 0.8746 - auc: 0.9496 - val_loss: 0.5117 - val_accuracy: 0.8073 - val_auc: 0.8863\n",
      "Epoch 64/100\n",
      "763/763 [==============================] - 6s 8ms/step - loss: 0.2837 - accuracy: 0.8769 - auc: 0.9511 - val_loss: 0.5326 - val_accuracy: 0.7945 - val_auc: 0.8824\n",
      "Epoch 65/100\n",
      "763/763 [==============================] - 7s 9ms/step - loss: 0.2842 - accuracy: 0.8748 - auc: 0.9510 - val_loss: 0.5126 - val_accuracy: 0.8075 - val_auc: 0.8836\n",
      "Epoch 66/100\n",
      "763/763 [==============================] - 6s 8ms/step - loss: 0.2734 - accuracy: 0.8812 - auc: 0.9545 - val_loss: 0.5322 - val_accuracy: 0.8026 - val_auc: 0.8812\n",
      "Epoch 67/100\n",
      "763/763 [==============================] - 7s 9ms/step - loss: 0.2746 - accuracy: 0.8807 - auc: 0.9545 - val_loss: 0.5056 - val_accuracy: 0.8087 - val_auc: 0.8877\n",
      "Epoch 68/100\n",
      "763/763 [==============================] - 7s 9ms/step - loss: 0.2675 - accuracy: 0.8828 - auc: 0.9561 - val_loss: 0.5002 - val_accuracy: 0.8170 - val_auc: 0.8899\n",
      "Epoch 69/100\n",
      "763/763 [==============================] - 6s 8ms/step - loss: 0.2695 - accuracy: 0.8820 - auc: 0.9559 - val_loss: 0.5177 - val_accuracy: 0.8094 - val_auc: 0.8892\n",
      "Epoch 70/100\n",
      "763/763 [==============================] - 6s 8ms/step - loss: 0.2596 - accuracy: 0.8879 - auc: 0.9588 - val_loss: 0.5231 - val_accuracy: 0.8145 - val_auc: 0.8882\n",
      "Epoch 71/100\n",
      "763/763 [==============================] - 7s 9ms/step - loss: 0.2565 - accuracy: 0.8880 - auc: 0.9598 - val_loss: 0.5319 - val_accuracy: 0.8166 - val_auc: 0.8884\n",
      "Epoch 72/100\n",
      "763/763 [==============================] - 7s 9ms/step - loss: 0.2550 - accuracy: 0.8875 - auc: 0.9601 - val_loss: 0.5363 - val_accuracy: 0.8124 - val_auc: 0.8899\n",
      "Epoch 73/100\n",
      "763/763 [==============================] - 7s 9ms/step - loss: 0.2517 - accuracy: 0.8896 - auc: 0.9610 - val_loss: 0.5518 - val_accuracy: 0.8087 - val_auc: 0.8862\n",
      "Epoch 74/100\n",
      "763/763 [==============================] - 7s 9ms/step - loss: 0.2467 - accuracy: 0.8932 - auc: 0.9630 - val_loss: 0.5280 - val_accuracy: 0.8138 - val_auc: 0.8902\n",
      "Epoch 75/100\n",
      "763/763 [==============================] - 6s 8ms/step - loss: 0.2422 - accuracy: 0.8959 - auc: 0.9641 - val_loss: 0.5533 - val_accuracy: 0.8191 - val_auc: 0.8917\n",
      "Epoch 76/100\n",
      "763/763 [==============================] - 7s 9ms/step - loss: 0.2421 - accuracy: 0.8956 - auc: 0.9642 - val_loss: 0.5623 - val_accuracy: 0.8187 - val_auc: 0.8877\n",
      "Epoch 77/100\n",
      "763/763 [==============================] - 6s 8ms/step - loss: 0.2458 - accuracy: 0.8977 - auc: 0.9649 - val_loss: 0.5109 - val_accuracy: 0.8231 - val_auc: 0.8953\n",
      "Epoch 78/100\n",
      "763/763 [==============================] - 7s 9ms/step - loss: 0.2336 - accuracy: 0.9013 - auc: 0.9669 - val_loss: 0.5264 - val_accuracy: 0.8249 - val_auc: 0.8961\n",
      "Epoch 79/100\n",
      "763/763 [==============================] - 7s 9ms/step - loss: 0.2327 - accuracy: 0.9013 - auc: 0.9671 - val_loss: 0.5324 - val_accuracy: 0.8210 - val_auc: 0.8949\n",
      "Epoch 80/100\n",
      "763/763 [==============================] - 7s 9ms/step - loss: 0.2303 - accuracy: 0.9006 - auc: 0.9676 - val_loss: 0.5248 - val_accuracy: 0.8231 - val_auc: 0.8969\n",
      "Epoch 81/100\n",
      "763/763 [==============================] - 7s 9ms/step - loss: 0.2296 - accuracy: 0.9027 - auc: 0.9683 - val_loss: 0.5427 - val_accuracy: 0.8266 - val_auc: 0.8966\n",
      "Epoch 82/100\n",
      "763/763 [==============================] - 8s 10ms/step - loss: 0.2228 - accuracy: 0.9066 - auc: 0.9700 - val_loss: 0.5279 - val_accuracy: 0.8261 - val_auc: 0.8968\n",
      "Epoch 83/100\n",
      "763/763 [==============================] - 7s 9ms/step - loss: 0.2186 - accuracy: 0.9079 - auc: 0.9710 - val_loss: 0.5621 - val_accuracy: 0.8224 - val_auc: 0.8895\n",
      "Epoch 84/100\n",
      "763/763 [==============================] - 8s 10ms/step - loss: 0.2250 - accuracy: 0.9052 - auc: 0.9692 - val_loss: 0.5258 - val_accuracy: 0.8310 - val_auc: 0.8984\n",
      "Epoch 85/100\n",
      "763/763 [==============================] - 7s 9ms/step - loss: 0.2120 - accuracy: 0.9100 - auc: 0.9727 - val_loss: 0.5590 - val_accuracy: 0.8289 - val_auc: 0.8967\n",
      "Epoch 86/100\n",
      "763/763 [==============================] - 7s 9ms/step - loss: 0.2173 - accuracy: 0.9087 - auc: 0.9715 - val_loss: 0.5156 - val_accuracy: 0.8296 - val_auc: 0.9025\n",
      "Epoch 87/100\n",
      "763/763 [==============================] - 7s 9ms/step - loss: 0.2165 - accuracy: 0.9084 - auc: 0.9714 - val_loss: 0.5478 - val_accuracy: 0.8263 - val_auc: 0.9002\n",
      "Epoch 88/100\n",
      "763/763 [==============================] - 7s 9ms/step - loss: 0.2076 - accuracy: 0.9116 - auc: 0.9737 - val_loss: 0.5308 - val_accuracy: 0.8345 - val_auc: 0.9004\n",
      "Epoch 89/100\n",
      "763/763 [==============================] - 7s 9ms/step - loss: 0.1997 - accuracy: 0.9144 - auc: 0.9758 - val_loss: 0.5334 - val_accuracy: 0.8340 - val_auc: 0.9012\n",
      "Epoch 90/100\n",
      "763/763 [==============================] - 7s 9ms/step - loss: 0.2030 - accuracy: 0.9130 - auc: 0.9749 - val_loss: 0.5299 - val_accuracy: 0.8352 - val_auc: 0.9010\n",
      "Epoch 91/100\n",
      "763/763 [==============================] - 6s 8ms/step - loss: 0.2014 - accuracy: 0.9168 - auc: 0.9753 - val_loss: 0.5452 - val_accuracy: 0.8324 - val_auc: 0.9014\n",
      "Epoch 92/100\n",
      "763/763 [==============================] - 6s 8ms/step - loss: 0.2010 - accuracy: 0.9184 - auc: 0.9754 - val_loss: 0.5692 - val_accuracy: 0.8335 - val_auc: 0.8998\n",
      "Epoch 93/100\n",
      "763/763 [==============================] - 7s 9ms/step - loss: 0.1972 - accuracy: 0.9171 - auc: 0.9763 - val_loss: 0.5537 - val_accuracy: 0.8356 - val_auc: 0.9004\n",
      "Epoch 94/100\n",
      "763/763 [==============================] - 7s 9ms/step - loss: 0.2030 - accuracy: 0.9182 - auc: 0.9754 - val_loss: 0.5769 - val_accuracy: 0.8342 - val_auc: 0.8990\n",
      "Epoch 95/100\n",
      "763/763 [==============================] - 6s 8ms/step - loss: 0.1935 - accuracy: 0.9202 - auc: 0.9772 - val_loss: 0.5548 - val_accuracy: 0.8368 - val_auc: 0.9016\n",
      "Epoch 96/100\n",
      "763/763 [==============================] - 7s 9ms/step - loss: 0.1915 - accuracy: 0.9221 - auc: 0.9778 - val_loss: 0.5761 - val_accuracy: 0.8268 - val_auc: 0.9006\n",
      "Epoch 97/100\n",
      "763/763 [==============================] - 7s 9ms/step - loss: 0.1925 - accuracy: 0.9196 - auc: 0.9774 - val_loss: 0.5517 - val_accuracy: 0.8352 - val_auc: 0.9033\n",
      "Epoch 98/100\n",
      "763/763 [==============================] - 6s 8ms/step - loss: 0.1926 - accuracy: 0.9221 - auc: 0.9776 - val_loss: 0.5883 - val_accuracy: 0.8405 - val_auc: 0.9026\n",
      "Epoch 99/100\n",
      "763/763 [==============================] - 6s 8ms/step - loss: 0.1877 - accuracy: 0.9221 - auc: 0.9789 - val_loss: 0.6032 - val_accuracy: 0.8338 - val_auc: 0.9015\n",
      "Epoch 100/100\n",
      "763/763 [==============================] - 7s 9ms/step - loss: 0.1835 - accuracy: 0.9241 - auc: 0.9795 - val_loss: 0.5718 - val_accuracy: 0.8405 - val_auc: 0.9037\n",
      "135/135 [==============================] - 0s 2ms/step\n",
      "ROC-AUC: 0.9051315248114697\n",
      "Accuracy: 0.8404922219642442\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, LSTM, Dropout, Input, concatenate\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "dropout=0.05\n",
    "lstm_units = 256\n",
    "lstm_units2 = 128\n",
    "dense_units = 64\n",
    "\n",
    "\n",
    "# First branch for the LSTM\n",
    "lstm_input = Input(shape=(1, 100))\n",
    "lstm_output = LSTM(units=lstm_units, return_sequences=True, activation='relu')(lstm_input)\n",
    "lstm_output = Dropout(dropout)(lstm_output)\n",
    "lstm_output = LSTM(units=lstm_units2, activation='relu')(lstm_output)\n",
    "lstm_output = Dropout(dropout)(lstm_output)\n",
    "\n",
    "# Second branch for the dense layers\n",
    "dense_input = Input(shape=(5,))\n",
    "dense_output = Dense(units=dense_units, activation='relu')(dense_input)\n",
    "dense_output = Dropout(dropout)(dense_output)\n",
    "\n",
    "# Concatenate the outputs from both branches\n",
    "combined = concatenate([lstm_output, dense_output])\n",
    "\n",
    "combined = Dense(units = dense_units, activation='relu')(combined)\n",
    "\n",
    "# Final output layer\n",
    "output = Dense(units=1, activation='sigmoid')(combined)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=[lstm_input, dense_input], outputs=output)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', 'AUC'])\n",
    "\n",
    "# Define the early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model with both LSTM and dense input\n",
    "model.fit([X_train_vec, X_train], y_train, epochs=100, batch_size=32,\n",
    "          validation_data=([X_test_vec, X_test], y_test),\n",
    "          callbacks=[early_stopping])\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict([X_test_vec, X_test])\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "y_pred_class = (y_pred > .5).astype(int)\n",
    "accuracy = accuracy_score(y_test,y_pred_class)\n",
    "print('ROC-AUC:', roc_auc)\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "matrix = confusion_matrix(y_test, y_pred_class)\n",
    "\n",
    "sns.heatmap(matrix/np.sum(matrix), annot=True, fmt='.2%', cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59dc53ff-9c21-466a-8e9f-f10b3833b0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model containing character length, number of capital words, upvotes and # of comments\n",
    "#Model 2 adds POS tagging and standard scaling of variables\n",
    "#Only left in proper nouns as others decreased performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77a3b55f-1112-4739-b2cf-337ce0205e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "#create extra variables for later\n",
    "df_other_var = create_other_var(df)\n",
    "\n",
    "#Create simple dataframe with only text and predictor\n",
    "df = df[['Title','Political Lean']] \n",
    "\n",
    "#dummy code predictor\n",
    "df['Political Lean'] = df['Political Lean'].replace('Liberal',1)\n",
    "df['Political Lean'] = df['Political Lean'].replace('Conservative',0)\n",
    "\n",
    "df = df.rename({'Political Lean':'y'},axis=1) #replace column name for simplicity\n",
    "\n",
    "df = pd.concat([df,df_other_var],axis=1)\n",
    "\n",
    "df = df[df['Length']>=15]\n",
    "\n",
    "#Split into X & y\n",
    "X = df.drop(['y'],axis=1)\n",
    "y = df['y']\n",
    "\n",
    "#oversample minority class\n",
    "oversample = RandomOverSampler(sampling_strategy='minority', random_state=13)\n",
    "X, y = oversample.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eed9495c-923f-474f-9f74-dd19b9ac4074",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'merge'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m loss_df \u001b[38;5;241m=\u001b[39m \u001b[43mX_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m(X[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTitle\u001b[39m\u001b[38;5;124m'\u001b[39m]],left_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,right_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m loss_df \u001b[38;5;241m=\u001b[39m loss_df\u001b[38;5;241m.\u001b[39mmerge(y,left_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,right_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m predictions \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(y_pred, columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprob\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'merge'"
     ]
    }
   ],
   "source": [
    "loss_df = X_test.merge(X[['Title']],left_index=True,right_index=True,how='left')\n",
    "loss_df = loss_df.merge(y,left_index=True,right_index=True,how='left')\n",
    "predictions = pd.DataFrame(y_pred, columns = ['prob'])\n",
    "loss_df = pd.concat([loss_df,predictions.set_index(loss_df.index)],axis=1)\n",
    "loss_df['prob'] = abs(loss_df['prob']-.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83928af4-ce6f-427f-89a2-874bc4d50d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_df.sort_values(by='prob').head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ea316a-dd0e-403b-941b-a187813ce181",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LHL_env",
   "language": "python",
   "name": "lhl_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
