{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67233b73-f1a2-4cab-a395-0acf30fb4ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Andrew\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Andrew\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "df = pd.read_csv(\"../data/fulldata.csv\")\n",
    "df2 = pd.read_csv(\"../data/6_14_pull.csv\")\n",
    "\n",
    "df = pd.concat([df,df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a16c2532-c2f2-48f7-84f6-7f9e0049ea0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Cleaning import lowercase, unpunctuate, tokenize, lemmatize, count_capitalized_words, create_other_var, cleaning_and_prep, stack_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb47f54a-ec57-4308-a10d-62853364b7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andrew\\Documents\\LHL\\PoliticalNLP\\python\\Cleaning.py:127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Political Lean'] = df['Political Lean'].replace('Liberal',1)\n",
      "C:\\Users\\Andrew\\Documents\\LHL\\PoliticalNLP\\python\\Cleaning.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Political Lean'] = df['Political Lean'].replace('Conservative',0)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = cleaning_and_prep(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c07ff43-bee3-4c11-9e29-29c25764a85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vec, X_test_vec, X_train, X_test = stack_vectors(X_train,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83645586-d576-4de0-ae1e-d3897c0b206b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "763/763 [==============================] - 17s 16ms/step - loss: 0.6286 - accuracy: 0.6413 - auc: 0.7039 - val_loss: 0.6007 - val_accuracy: 0.6710 - val_auc: 0.7550\n",
      "Epoch 2/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.5839 - accuracy: 0.6812 - auc: 0.7579 - val_loss: 0.5733 - val_accuracy: 0.6886 - val_auc: 0.7716\n",
      "Epoch 3/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.5697 - accuracy: 0.6937 - auc: 0.7699 - val_loss: 0.5817 - val_accuracy: 0.6745 - val_auc: 0.7776\n",
      "Epoch 4/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.5612 - accuracy: 0.7041 - auc: 0.7799 - val_loss: 0.5536 - val_accuracy: 0.7100 - val_auc: 0.7888\n",
      "Epoch 5/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.5554 - accuracy: 0.7016 - auc: 0.7844 - val_loss: 0.5551 - val_accuracy: 0.7079 - val_auc: 0.7896\n",
      "Epoch 6/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.5520 - accuracy: 0.7085 - auc: 0.7881 - val_loss: 0.5475 - val_accuracy: 0.7133 - val_auc: 0.7939\n",
      "Epoch 7/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.5472 - accuracy: 0.7138 - auc: 0.7922 - val_loss: 0.5442 - val_accuracy: 0.7170 - val_auc: 0.7975\n",
      "Epoch 8/100\n",
      "763/763 [==============================] - 12s 15ms/step - loss: 0.5432 - accuracy: 0.7154 - auc: 0.7962 - val_loss: 0.5441 - val_accuracy: 0.7156 - val_auc: 0.7996\n",
      "Epoch 9/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.5398 - accuracy: 0.7195 - auc: 0.7993 - val_loss: 0.5440 - val_accuracy: 0.7165 - val_auc: 0.8004\n",
      "Epoch 10/100\n",
      "763/763 [==============================] - 14s 19ms/step - loss: 0.5359 - accuracy: 0.7225 - auc: 0.8024 - val_loss: 0.5499 - val_accuracy: 0.7095 - val_auc: 0.7982\n",
      "Epoch 11/100\n",
      "763/763 [==============================] - 18s 24ms/step - loss: 0.5332 - accuracy: 0.7232 - auc: 0.8046 - val_loss: 0.5389 - val_accuracy: 0.7172 - val_auc: 0.8028\n",
      "Epoch 12/100\n",
      "763/763 [==============================] - 13s 16ms/step - loss: 0.5302 - accuracy: 0.7229 - auc: 0.8068 - val_loss: 0.5381 - val_accuracy: 0.7239 - val_auc: 0.8046\n",
      "Epoch 13/100\n",
      "763/763 [==============================] - 13s 17ms/step - loss: 0.5270 - accuracy: 0.7256 - auc: 0.8092 - val_loss: 0.5403 - val_accuracy: 0.7209 - val_auc: 0.8048\n",
      "Epoch 14/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.5222 - accuracy: 0.7299 - auc: 0.8129 - val_loss: 0.5347 - val_accuracy: 0.7251 - val_auc: 0.8095\n",
      "Epoch 15/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.5238 - accuracy: 0.7306 - auc: 0.8134 - val_loss: 0.5423 - val_accuracy: 0.7121 - val_auc: 0.8062\n",
      "Epoch 16/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.5218 - accuracy: 0.7334 - auc: 0.8134 - val_loss: 0.5304 - val_accuracy: 0.7237 - val_auc: 0.8115\n",
      "Epoch 17/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.5163 - accuracy: 0.7317 - auc: 0.8177 - val_loss: 0.5335 - val_accuracy: 0.7263 - val_auc: 0.8103\n",
      "Epoch 18/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.5181 - accuracy: 0.7324 - auc: 0.8167 - val_loss: 0.5284 - val_accuracy: 0.7321 - val_auc: 0.8141\n",
      "Epoch 19/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.5166 - accuracy: 0.7374 - auc: 0.8184 - val_loss: 0.5244 - val_accuracy: 0.7302 - val_auc: 0.8198\n",
      "Epoch 20/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.5125 - accuracy: 0.7406 - auc: 0.8216 - val_loss: 0.5324 - val_accuracy: 0.7330 - val_auc: 0.8151\n",
      "Epoch 21/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.5132 - accuracy: 0.7366 - auc: 0.8208 - val_loss: 0.5240 - val_accuracy: 0.7335 - val_auc: 0.8173\n",
      "Epoch 22/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.5115 - accuracy: 0.7382 - auc: 0.8222 - val_loss: 0.5208 - val_accuracy: 0.7297 - val_auc: 0.8202\n",
      "Epoch 23/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.5077 - accuracy: 0.7399 - auc: 0.8254 - val_loss: 0.5168 - val_accuracy: 0.7355 - val_auc: 0.8206\n",
      "Epoch 24/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.5101 - accuracy: 0.7462 - auc: 0.8253 - val_loss: 0.5212 - val_accuracy: 0.7353 - val_auc: 0.8185\n",
      "Epoch 25/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.5070 - accuracy: 0.7425 - auc: 0.8263 - val_loss: 0.5228 - val_accuracy: 0.7367 - val_auc: 0.8171\n",
      "Epoch 26/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.5042 - accuracy: 0.7418 - auc: 0.8276 - val_loss: 0.5198 - val_accuracy: 0.7318 - val_auc: 0.8245\n",
      "Epoch 27/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.5006 - accuracy: 0.7439 - auc: 0.8311 - val_loss: 0.5229 - val_accuracy: 0.7407 - val_auc: 0.8224\n",
      "Epoch 28/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.5003 - accuracy: 0.7419 - auc: 0.8303 - val_loss: 0.5125 - val_accuracy: 0.7416 - val_auc: 0.8281\n",
      "Epoch 29/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.5005 - accuracy: 0.7474 - auc: 0.8306 - val_loss: 0.5188 - val_accuracy: 0.7395 - val_auc: 0.8247\n",
      "Epoch 30/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.4984 - accuracy: 0.7475 - auc: 0.8328 - val_loss: 0.5174 - val_accuracy: 0.7372 - val_auc: 0.8260\n",
      "Epoch 31/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.4980 - accuracy: 0.7478 - auc: 0.8327 - val_loss: 0.5113 - val_accuracy: 0.7388 - val_auc: 0.8281\n",
      "Epoch 32/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.4976 - accuracy: 0.7478 - auc: 0.8333 - val_loss: 0.5119 - val_accuracy: 0.7420 - val_auc: 0.8296\n",
      "Epoch 33/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.4932 - accuracy: 0.7526 - auc: 0.8364 - val_loss: 0.5129 - val_accuracy: 0.7379 - val_auc: 0.8290\n",
      "Epoch 34/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.4940 - accuracy: 0.7516 - auc: 0.8357 - val_loss: 0.5130 - val_accuracy: 0.7349 - val_auc: 0.8317\n",
      "Epoch 35/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.4894 - accuracy: 0.7529 - auc: 0.8382 - val_loss: 0.5123 - val_accuracy: 0.7395 - val_auc: 0.8278\n",
      "Epoch 36/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.4907 - accuracy: 0.7520 - auc: 0.8377 - val_loss: 0.5073 - val_accuracy: 0.7497 - val_auc: 0.8315\n",
      "Epoch 37/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.4869 - accuracy: 0.7570 - auc: 0.8412 - val_loss: 0.5128 - val_accuracy: 0.7390 - val_auc: 0.8281\n",
      "Epoch 38/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.4868 - accuracy: 0.7523 - auc: 0.8399 - val_loss: 0.5051 - val_accuracy: 0.7462 - val_auc: 0.8362\n",
      "Epoch 39/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.4822 - accuracy: 0.7551 - auc: 0.8440 - val_loss: 0.5073 - val_accuracy: 0.7472 - val_auc: 0.8383\n",
      "Epoch 40/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.4856 - accuracy: 0.7554 - auc: 0.8423 - val_loss: 0.5084 - val_accuracy: 0.7455 - val_auc: 0.8319\n",
      "Epoch 41/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.4835 - accuracy: 0.7569 - auc: 0.8441 - val_loss: 0.5028 - val_accuracy: 0.7495 - val_auc: 0.8349\n",
      "Epoch 42/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.4805 - accuracy: 0.7569 - auc: 0.8447 - val_loss: 0.5097 - val_accuracy: 0.7446 - val_auc: 0.8339\n",
      "Epoch 43/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.4784 - accuracy: 0.7583 - auc: 0.8467 - val_loss: 0.5046 - val_accuracy: 0.7425 - val_auc: 0.8323\n",
      "Epoch 44/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.4784 - accuracy: 0.7580 - auc: 0.8470 - val_loss: 0.5062 - val_accuracy: 0.7492 - val_auc: 0.8361\n",
      "Epoch 45/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.4770 - accuracy: 0.7584 - auc: 0.8471 - val_loss: 0.5189 - val_accuracy: 0.7362 - val_auc: 0.8335\n",
      "Epoch 46/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.4737 - accuracy: 0.7596 - auc: 0.8494 - val_loss: 0.4944 - val_accuracy: 0.7509 - val_auc: 0.8425\n",
      "Epoch 47/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.4717 - accuracy: 0.7628 - auc: 0.8518 - val_loss: 0.4989 - val_accuracy: 0.7483 - val_auc: 0.8368\n",
      "Epoch 48/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.4734 - accuracy: 0.7645 - auc: 0.8511 - val_loss: 0.5115 - val_accuracy: 0.7446 - val_auc: 0.8345\n",
      "Epoch 49/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.4698 - accuracy: 0.7642 - auc: 0.8526 - val_loss: 0.5027 - val_accuracy: 0.7516 - val_auc: 0.8426\n",
      "Epoch 50/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.4675 - accuracy: 0.7626 - auc: 0.8536 - val_loss: 0.4950 - val_accuracy: 0.7564 - val_auc: 0.8445\n",
      "Epoch 51/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.4645 - accuracy: 0.7698 - auc: 0.8565 - val_loss: 0.4988 - val_accuracy: 0.7557 - val_auc: 0.8426\n",
      "Epoch 52/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.4677 - accuracy: 0.7681 - auc: 0.8549 - val_loss: 0.4963 - val_accuracy: 0.7560 - val_auc: 0.8427\n",
      "Epoch 53/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.4668 - accuracy: 0.7665 - auc: 0.8544 - val_loss: 0.4919 - val_accuracy: 0.7527 - val_auc: 0.8438\n",
      "Epoch 54/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.4650 - accuracy: 0.7694 - auc: 0.8564 - val_loss: 0.4934 - val_accuracy: 0.7562 - val_auc: 0.8431\n",
      "Epoch 55/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.4577 - accuracy: 0.7738 - auc: 0.8608 - val_loss: 0.4980 - val_accuracy: 0.7537 - val_auc: 0.8435\n",
      "Epoch 56/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.4620 - accuracy: 0.7723 - auc: 0.8600 - val_loss: 0.5010 - val_accuracy: 0.7557 - val_auc: 0.8437\n",
      "Epoch 57/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.4584 - accuracy: 0.7728 - auc: 0.8607 - val_loss: 0.4941 - val_accuracy: 0.7629 - val_auc: 0.8477\n",
      "Epoch 58/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.4542 - accuracy: 0.7764 - auc: 0.8638 - val_loss: 0.5190 - val_accuracy: 0.7560 - val_auc: 0.8442\n",
      "Epoch 59/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.4562 - accuracy: 0.7771 - auc: 0.8628 - val_loss: 0.4896 - val_accuracy: 0.7550 - val_auc: 0.8460\n",
      "Epoch 60/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.4563 - accuracy: 0.7761 - auc: 0.8638 - val_loss: 0.4899 - val_accuracy: 0.7616 - val_auc: 0.8480\n",
      "Epoch 61/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.4561 - accuracy: 0.7759 - auc: 0.8629 - val_loss: 0.4941 - val_accuracy: 0.7602 - val_auc: 0.8462\n",
      "Epoch 62/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.4499 - accuracy: 0.7783 - auc: 0.8667 - val_loss: 0.4945 - val_accuracy: 0.7578 - val_auc: 0.8451\n",
      "Epoch 63/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.4506 - accuracy: 0.7782 - auc: 0.8671 - val_loss: 0.4933 - val_accuracy: 0.7590 - val_auc: 0.8486\n",
      "Epoch 64/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.4479 - accuracy: 0.7798 - auc: 0.8674 - val_loss: 0.4835 - val_accuracy: 0.7604 - val_auc: 0.8493\n",
      "Epoch 65/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.4452 - accuracy: 0.7810 - auc: 0.8695 - val_loss: 0.4809 - val_accuracy: 0.7606 - val_auc: 0.8503\n",
      "Epoch 66/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.4443 - accuracy: 0.7778 - auc: 0.8695 - val_loss: 0.4967 - val_accuracy: 0.7669 - val_auc: 0.8491\n",
      "Epoch 67/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.4427 - accuracy: 0.7832 - auc: 0.8712 - val_loss: 0.4856 - val_accuracy: 0.7690 - val_auc: 0.8535\n",
      "Epoch 68/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.4397 - accuracy: 0.7866 - auc: 0.8731 - val_loss: 0.4908 - val_accuracy: 0.7669 - val_auc: 0.8498\n",
      "Epoch 69/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.4389 - accuracy: 0.7848 - auc: 0.8734 - val_loss: 0.4875 - val_accuracy: 0.7708 - val_auc: 0.8529\n",
      "Epoch 70/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.4362 - accuracy: 0.7890 - auc: 0.8753 - val_loss: 0.4863 - val_accuracy: 0.7697 - val_auc: 0.8539\n",
      "Epoch 71/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.4380 - accuracy: 0.7860 - auc: 0.8749 - val_loss: 0.4880 - val_accuracy: 0.7694 - val_auc: 0.8574\n",
      "Epoch 72/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.4366 - accuracy: 0.7871 - auc: 0.8756 - val_loss: 0.4933 - val_accuracy: 0.7636 - val_auc: 0.8505\n",
      "Epoch 73/100\n",
      "763/763 [==============================] - 13s 17ms/step - loss: 0.4340 - accuracy: 0.7871 - auc: 0.8769 - val_loss: 0.4893 - val_accuracy: 0.7692 - val_auc: 0.8517\n",
      "Epoch 74/100\n",
      "763/763 [==============================] - 13s 17ms/step - loss: 0.4352 - accuracy: 0.7892 - auc: 0.8762 - val_loss: 0.4867 - val_accuracy: 0.7669 - val_auc: 0.8550\n",
      "Epoch 75/100\n",
      "763/763 [==============================] - 14s 18ms/step - loss: 0.4342 - accuracy: 0.7882 - auc: 0.8767 - val_loss: 0.4836 - val_accuracy: 0.7743 - val_auc: 0.8565\n",
      "Epoch 76/100\n",
      "763/763 [==============================] - 14s 18ms/step - loss: 0.4283 - accuracy: 0.7905 - auc: 0.8809 - val_loss: 0.4807 - val_accuracy: 0.7750 - val_auc: 0.8586\n",
      "Epoch 77/100\n",
      "763/763 [==============================] - 14s 18ms/step - loss: 0.4269 - accuracy: 0.7932 - auc: 0.8810 - val_loss: 0.4822 - val_accuracy: 0.7699 - val_auc: 0.8580\n",
      "Epoch 78/100\n",
      "763/763 [==============================] - 14s 18ms/step - loss: 0.4251 - accuracy: 0.7941 - auc: 0.8826 - val_loss: 0.4782 - val_accuracy: 0.7727 - val_auc: 0.8591\n",
      "Epoch 79/100\n",
      "763/763 [==============================] - 13s 17ms/step - loss: 0.4254 - accuracy: 0.7938 - auc: 0.8823 - val_loss: 0.4788 - val_accuracy: 0.7773 - val_auc: 0.8610\n",
      "Epoch 80/100\n",
      "763/763 [==============================] - 13s 17ms/step - loss: 0.4237 - accuracy: 0.7960 - auc: 0.8837 - val_loss: 0.4806 - val_accuracy: 0.7783 - val_auc: 0.8599\n",
      "Epoch 81/100\n",
      "763/763 [==============================] - 15s 20ms/step - loss: 0.4172 - accuracy: 0.7979 - auc: 0.8862 - val_loss: 0.4829 - val_accuracy: 0.7785 - val_auc: 0.8619\n",
      "Epoch 82/100\n",
      "763/763 [==============================] - 14s 18ms/step - loss: 0.4226 - accuracy: 0.7969 - auc: 0.8838 - val_loss: 0.4807 - val_accuracy: 0.7811 - val_auc: 0.8593\n",
      "Epoch 83/100\n",
      "763/763 [==============================] - 14s 18ms/step - loss: 0.4183 - accuracy: 0.7982 - auc: 0.8863 - val_loss: 0.4716 - val_accuracy: 0.7808 - val_auc: 0.8635\n",
      "Epoch 84/100\n",
      "763/763 [==============================] - 15s 19ms/step - loss: 0.4166 - accuracy: 0.7994 - auc: 0.8874 - val_loss: 0.4721 - val_accuracy: 0.7783 - val_auc: 0.8622\n",
      "Epoch 85/100\n",
      "763/763 [==============================] - 14s 18ms/step - loss: 0.4146 - accuracy: 0.7999 - auc: 0.8882 - val_loss: 0.4744 - val_accuracy: 0.7880 - val_auc: 0.8666\n",
      "Epoch 86/100\n",
      "763/763 [==============================] - 14s 18ms/step - loss: 0.4243 - accuracy: 0.7994 - auc: 0.8869 - val_loss: 0.4638 - val_accuracy: 0.7822 - val_auc: 0.8652\n",
      "Epoch 87/100\n",
      "763/763 [==============================] - 14s 18ms/step - loss: 0.4137 - accuracy: 0.7982 - auc: 0.8894 - val_loss: 0.4761 - val_accuracy: 0.7827 - val_auc: 0.8649\n",
      "Epoch 88/100\n",
      "763/763 [==============================] - 13s 17ms/step - loss: 0.4127 - accuracy: 0.8027 - auc: 0.8900 - val_loss: 0.4794 - val_accuracy: 0.7762 - val_auc: 0.8683\n",
      "Epoch 89/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.4111 - accuracy: 0.8017 - auc: 0.8903 - val_loss: 0.4672 - val_accuracy: 0.7850 - val_auc: 0.8682\n",
      "Epoch 90/100\n",
      "763/763 [==============================] - 13s 17ms/step - loss: 0.4075 - accuracy: 0.8047 - auc: 0.8926 - val_loss: 0.4666 - val_accuracy: 0.7957 - val_auc: 0.8729\n",
      "Epoch 91/100\n",
      "763/763 [==============================] - 13s 18ms/step - loss: 0.4099 - accuracy: 0.8050 - auc: 0.8916 - val_loss: 0.4769 - val_accuracy: 0.7831 - val_auc: 0.8659\n",
      "Epoch 92/100\n",
      "763/763 [==============================] - 13s 17ms/step - loss: 0.4035 - accuracy: 0.8067 - auc: 0.8949 - val_loss: 0.4762 - val_accuracy: 0.7906 - val_auc: 0.8713\n",
      "Epoch 93/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.4149 - accuracy: 0.8044 - auc: 0.8927 - val_loss: 0.4658 - val_accuracy: 0.7869 - val_auc: 0.8704\n",
      "Epoch 94/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.4036 - accuracy: 0.8086 - auc: 0.8949 - val_loss: 0.4655 - val_accuracy: 0.7927 - val_auc: 0.8748\n",
      "Epoch 95/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.4026 - accuracy: 0.8091 - auc: 0.8960 - val_loss: 0.4805 - val_accuracy: 0.7850 - val_auc: 0.8670\n",
      "Epoch 96/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.3990 - accuracy: 0.8132 - auc: 0.8983 - val_loss: 0.4710 - val_accuracy: 0.7845 - val_auc: 0.8723\n",
      "Epoch 97/100\n",
      "763/763 [==============================] - 12s 16ms/step - loss: 0.4003 - accuracy: 0.8089 - auc: 0.8971 - val_loss: 0.4667 - val_accuracy: 0.7864 - val_auc: 0.8713\n",
      "Epoch 98/100\n",
      "763/763 [==============================] - 13s 17ms/step - loss: 0.3962 - accuracy: 0.8125 - auc: 0.8992 - val_loss: 0.4714 - val_accuracy: 0.7889 - val_auc: 0.8694\n",
      "Epoch 99/100\n",
      "763/763 [==============================] - 13s 17ms/step - loss: 0.3963 - accuracy: 0.8092 - auc: 0.8989 - val_loss: 0.4652 - val_accuracy: 0.7950 - val_auc: 0.8761\n",
      "Epoch 100/100\n",
      "763/763 [==============================] - 13s 17ms/step - loss: 0.3945 - accuracy: 0.8108 - auc: 0.9001 - val_loss: 0.4665 - val_accuracy: 0.7964 - val_auc: 0.8751\n",
      "135/135 [==============================] - 1s 3ms/step\n",
      "ROC-AUC: 0.8751167685201557\n",
      "Accuracy: 0.796377989319712\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgwAAAGdCAYAAAB+VCt0AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA1SklEQVR4nO3de1zUVf7H8fcAMhglqehoiUTqimh5AeOWVpYkWyZrm3TD2jSjtJXY2o3FeyXaTfOCm9VqtkVsmZctLbGtVQPdIrDsqqmhCCLeEFcHgfn94Ta78/2iw9jwg63Xs8f38YjzPXPmzPTQPnw+55yvxeFwOAQAAHAWPs09AQAA0PIRMAAAALcIGAAAgFsEDAAAwC0CBgAA4BYBAwAAcIuAAQAAuEXAAAAA3CJgAAAAbvk19wR+0Lr/hOaeAtDiHP54QXNPAWiRApr4/17e/H/SiaKfxp/jFhMwAADQYlhIwBvxjQAAALfIMAAAYGSxNPcMWhwCBgAAjChJmBAwAABgRIbBhBAKAAC4RYYBAAAjShImBAwAABhRkjAhhAIAAG6RYQAAwIiShAkBAwAARpQkTAihAACAW2QYAAAwoiRhwjcCAICRxeK9y0PZ2dkKCwtTQECAIiMjtXHjxka97qOPPpKfn5/69etnurd8+XJFRETIarUqIiJCK1as8HheBAwAALQQubm5SktLU2ZmpoqKijRo0CAlJiaqpKTkrK87evSoRo8erWuvvdZ0r6CgQMnJyUpJSdHWrVuVkpKiUaNGacuWLR7NzeJwOBwevaKJePPZ48BPxeGPFzT3FIAWKaCJC+qtr5zstbFObHqs0X2jo6M1YMAALVq0yNnWq1cvJSUlKSsr64yvu/XWW9WjRw/5+vpq5cqVKi4udt5LTk5WVVWV1q5d62wbNmyY2rZtq5ycnEbPjQwDAABGXixJ2O12VVVVuVx2u930ljU1NSosLFRCQoJLe0JCgvLz88841SVLlui7777T1KlTG7xfUFBgGvP6668/65gNIWAAAMDI4uO1KysrS0FBQS5XQ9mCyspK1dXVyWazubTbbDaVl5c3OM3t27fr0Ucf1auvvio/v4bTLuXl5R6NeSbskgAAoAllZGQoPT3dpc1qtZ6xv8WwUNLhcJjaJKmurk633367pk+frl/84hdnnUNjxzwbAgYAAIy8uK3SarWeNUD4QXBwsHx9fU2/+VdUVJgyBJJ07NgxffLJJyoqKtKECafXAdbX18vhcMjPz0/r1q3TkCFD1KlTp0aPeTaUJAAAMPKxeO9qJH9/f0VGRiovL8+lPS8vT3Fxcab+bdq00eeff67i4mLnlZqaqp49e6q4uFjR0dGSpNjYWNOY69ata3DMsyHDAABAC5Genq6UlBRFRUUpNjZWixcvVklJiVJTUyWdLm+UlpZq2bJl8vHxUZ8+fVxe37FjRwUEBLi0T5w4UYMHD9bs2bM1YsQIrVq1SuvXr9emTZs8mhsBAwAARs100mNycrIOHjyoGTNmqKysTH369NGaNWsUGhoqSSorK3N7JoNRXFycXn/9dU2aNEmTJ09Wt27dlJub68xANBbnMAAtGOcwAA1r8nMYrp3ptbFOvP9Hr43VnFjDAAAA3KIkAQCAEQ+fMiFgAADA6BweGvVTRwgFAADcIsMAAIARJQkTAgYAAIwoSZgQMAAAYESGwYRvBAAAuEWGAQAAI0oSJgQMAAAYUZIw4RsBAABukWEAAMCIkoQJAQMAAEaUJEz4RgAAgFtkGAAAMCLDYELAAACAEWsYTAihAACAW2QYAAAwoiRhQsAAAIARJQkTAgYAAIzIMJjwjQAAALfIMAAAYERJwoSAAQAAAwsBgwklCQAA4BYZBgAADMgwmBEwAABgRLxgQkkCAAC4RYYBAAADShJmBAwAABgQMJhRkgAAAG6RYQAAwIAMgxkBAwAABgQMZgQMAAAYES+YsIYBAAC4RYYBAAADShJmBAwAABgQMJhRkgAAAG6RYQAAwIAMgxkBAwAABgQMZpQkAACAW2QYAAAwIsFgQsAAAIABJQkzShIAAMAtMgwAABiQYTAjwwAAgIHFYvHa5ans7GyFhYUpICBAkZGR2rhx4xn7btq0SfHx8Wrfvr1at26t8PBwzZkzx6XP0qVLG5zXyZMnPZoXGQYAAIyaKcGQm5urtLQ0ZWdnKz4+Xs8//7wSExP15ZdfqmvXrqb+gYGBmjBhgi6//HIFBgZq06ZNuu+++xQYGKhx48Y5+7Vp00bffPONy2sDAgI8mpvF4XA4zu1jeVfr/hOaewpAi3P44wXNPQWgRQpo4l93O475q9fGqnhpVKP7RkdHa8CAAVq0aJGzrVevXkpKSlJWVlajxhg5cqQCAwP1yiuvSDqdYUhLS9ORI0c8mrcRJQkAAAy8WZKw2+2qqqpyuex2u+k9a2pqVFhYqISEBJf2hIQE5efnN2reRUVFys/P11VXXeXSXl1drdDQUHXp0kU33nijioqKPP5OCBgAADDwZsCQlZWloKAgl6uhbEFlZaXq6upks9lc2m02m8rLy8863y5dushqtSoqKkrjx4/X2LFjnffCw8O1dOlSrV69Wjk5OQoICFB8fLy2b9/u0XfCGgYAAJpQRkaG0tPTXdqsVusZ+xsXSjocDreLJzdu3Kjq6mpt3rxZjz76qLp3767bbrtNkhQTE6OYmBhn3/j4eA0YMEDz58/XvHnzGv05CBgAADDw5rZKq9V61gDhB8HBwfL19TVlEyoqKkxZB6OwsDBJ0mWXXab9+/dr2rRpzoDByMfHRwMHDvQ4w0BJAgAAg+bYVunv76/IyEjl5eW5tOfl5SkuLq7R4zgcjgbXSPz3/eLiYnXu3LnRY0pkGAAAaDHS09OVkpKiqKgoxcbGavHixSopKVFqaqqk0+WN0tJSLVu2TJK0cOFCde3aVeHh4ZJOn8vw9NNP68EHH3SOOX36dMXExKhHjx6qqqrSvHnzVFxcrIULF3o0NwIGAACMmukchuTkZB08eFAzZsxQWVmZ+vTpozVr1ig0NFSSVFZWppKSEmf/+vp6ZWRkaNeuXfLz81O3bt00a9Ys3Xfffc4+R44c0bhx41ReXq6goCD1799fGzZs0BVXXOHR3DiHAWjBOIcBaFhTn8Nw8f0rvDZW6aJfeW2s5sQaBgAA4BYlCQAADHj4lBkBAwAABgQMZgQMAAAYES+YsIYBAAC4RYYBAAADShJmZBj+hz18T4JOFC3QUw/f7GwbMaSvVi8crz1/n6UTRQt0+S8udjvOey9M1ImiBabrrXmpLv3G3TJIX709TYc3z9FHr/5e8f27udxPS7lWu9fP1O71M/XgHde43BvYJ1Qfvfp7+fjwhxBNL3HoEPXt3dN0zXxs+hlf8/prryppeKKuGHC5brrhev1t1UqX+6dOndKfshfohmHXaWD/y3TLr27SRxs3uPR55+3VSrj2Kg2KvULPPj3b5V5p6V4N/+X1qq6u9trnRNNpjpMeWzoyDP+jIiO6aszIOH327V6X9vNa+6tg63d6a/2nWjTljkaNdevvXpB/K1/nz+2CAvXP3Ay9lfefx5/+OmGAnnrkZk3MylVB8U6NvflKrVzwgAbc/Lj2lB9W7+4XafL9N2jkxD/JYpHeei5V72/+Wl9+VyY/Px/Ny7xVEx7LUX19izj2Az9xr+a+qfq6OufPO3Zs131jf6Oh1w9rsP9fX39N8+Y+oynTH1efPpfp888/04ypk3RBmza6+pohkqQF8+bqnbdXa+r0xxUWdqnyP9qohyZO0Muvvq5evSJ0+PAhTZ8ySTOemKUuXbpowgP3KWpgtAZfdbUk6YkZ0zTxod/p/PPPb+qPDzQJMgz/gwJb+2vJzLv1wGM5OlJ1wuVezjsfK2vxu/r75m8aPd7hqn9p/8FjzuvamHD962SNS8Dw2zuHaOnKAi1dUaBvdu3XI08v197yw7r3lkGSpPAwm7ZtL9U/Pv5WH/7zW23bvk/hYZ0kSQ+Nvk4ffbpDhV+WNPj+gLe1a9dOwR06OK8NH36gkJCuihrY8Ml2b/9ttX49KlnDEn+pLiEhSvzlDfrVyF9ryUsvOPu887dVGntvqgYNvkpdQkI06tbbFRd/pZYt/bMkae+evTr//As0LPGX6nPZ5Rp4RbR2frdDkrTm7b+pVatWum5oQtN/eHgFGQYzAob/QXMzkvXuxm36YEvjgwJP3JUUpzfe+1T/OlkjSWrl56v+vUL0fsFXLv3e3/yVYvqefkLath371D20o0I6tVXXzm3VPbSjvvhuny4NCVbKTTGatvDtJpkr4M6pmhq98/ZqJY28+Yx/edfU1Mjf3/VpgtaAAG37/HOdOnXq331Oyd/q79rHGqDiTz+VJIWGhurkyRP66qsvdfTIEX2x7XP1+EVPHT1yRNkL5ikjc0oTfDo0FQIGM49LEnv37tWiRYuUn5+v8vJyWSwW2Ww2xcXFKTU1VSEhIU0xT/zbLddHql94iK6888kmGT+qd6j69LhI909/1dkW3PZ8+fn5quLQMZe++w8ek619G0nSN7v2a+qCv+ntRaeP+J4yf7W+2bVf7/xpgjLnrtTQuF7KvO+XOlVbp4efelMfffpdk8wfMPr739fr2LFjuinpzMfzxsVfqRXL39SQa69Tr4je+vKLbVq5Yrlqa0/pyJHD6tCho+Lir9QrLy9VZNRAhYR01ZbNBfrwg/dV9+/SR5ugID02c7YmZfxB9pMnNfymJMVfOUhTJmXotjvuVGnpXv12wv2qra3V/Q9MOGN5BGipPAoYNm3apMTERIWEhCghIUEJCQlyOByqqKjQypUrNX/+fK1du1bx8fFnHcdut5sevemor5PFx/cMr4AkdbFdqKceuVnDH1goe01tk7zHXUmx2rZ9nz754nvTPeNTRywWi/77USQvvrlJL765yfnzncOjVX3cri2f7dLWlZN15Z1P6eKOF+qVWfco/IapqjnVNJ8B+G8rli9X/JWD1bGj7Yx9xqU+oMrKA0q5PVkOh0Pt2rfXTSN+paV/flE+//576fcZmZoxdZKSbkyUxWJRl5AQjUgaqVUr33KOc+11Q3XtdUOdP3/8zy3a8e23ysicouGJQzXrqWcVHBysO269RQOiBqp9+/ZN98Hx4/x0EgNe41HA8NBDD2ns2LGaM2fOGe+npaXp448/Pus4WVlZmj7ddbWyr22gWnX27MlZPzf9e3WVrX0b5b/6e2ebn5+vrhzQTanJgxUUnfajFhW2DmilW66P1GOL3nFprzxcrdraOtnaX+DS3rHd+aasww/aXxioP45L1NAxczXwsku04/sKfVdyQN+VHJCfn496hHbUFzv2nfNcgcbYt69UWzbn69nn5p+1X0BAgGY8nqXJU2fo0MGDCu7QQcvfyFVgYKDatm0r6fS6iLnzs2W323XkyBF17NhRc599Whdd3KXBMWtqajTzsemaOfsp7Sn5XrV1dc41FKGhl+jzz7Y6F1Si5fkplRK8xaM1DNu2bXM+k7sh9913n7Zt2+Z2nIyMDB09etTl8rNFejKVn6UP/vmNIn/9hKJvneW8Cr/4Xq+v+UTRt8760TsQbh46QFZ/P+WscQ34TtXWqeirPRoSE+7SPiQmXJu37mpwrKcevlnzX/1ApRVH5OtjkZ/ff7JHfr6+8mV7Jf4frFrxltq1a69Bg69uVP9WrVrJ1qmTfH199e7aNRp81TXy8XH9a9Jqtcpms6m2tlbv563TNUOubXCsxYsWKn7QYPWK6K26+nrV1f5n10Ztba3q6+vP+XMBzcGjDEPnzp2Vn5+vnj17Nni/oKBAnTt3djuO1WqV1eq6wIhyhHvV/7Lry+/KXNqOn6jRoaPHne1t25ynkE5t1bljkCTpF5ecTsPuP1il/QdPZwNefCxF+yqOasr81S5j3Z0Uq799+JkOHT1ueu95f/m7Xnp8tD79skRbPtulMSPjFdKpnV58c6Op75DocHXv2lFjJr8iSfpk2/fqeYlNCfER6mJrq7q6en37fcWP/DaAs6uvr9eqFW9p+Igk+fm5/lX33JxnVFGxX09knV4LtHv3Lm37/DNddnlfVR2t0ivLlmjH9u16bOYs52s++2yrKvbvV3h4L1VU7NeihfNV76jX3feMNb33jh3b9d67a5W7fKUkKSzsUvn4WPTW8jcUHNxBu3btVO8+lzXdh8ePRobBzKOA4eGHH1ZqaqoKCws1dOhQ2Ww2WSwWlZeXKy8vTy+++KLmzp3bRFNFY9xw1WV6YUaK8+dXZt8jSXr8T2v0xPNrJEkhndqZshHdu3ZU/IDuuiF1QYPjvrnuU7ULOl1m6BTcRl/sKFPSg9kqKTvs0i/A2kpzHr1FKX/4s3N9w74DR5X+5Bt6ftqdqjlVq3unvKKT9lNe+8xAQzYX5KusbJ+SRt5suld54IDKy/4TfNfX1WvZ0iX6fvcu+fn5aeAV0Vr2ao4u/q9yQ43droXz5mrv3j0677zzdOXgq/TErCfVpk0bl7EdDocemzpZD/8hQ+edd56kf5c8npilrMdnqKamRhmZU2SznXlNBZof8YKZxeEwLmU7u9zcXM2ZM0eFhYXO1cG+vr6KjIxUenq6Ro0adU4Tad1/wjm9DvgpO/xxwwEc8HMX0MTHDvZ45F2vjbX9qZ/GjhiPv/Lk5GQlJyfr1KlTqqyslCQFBwerVatWXp8cAABoGc45RmvVqlWj1isAAPC/hpKEGc+SAADAgEWPZhwNDQAA3CLDAACAAQkGMwIGAAAMfDhczoSSBAAAcIsMAwAABpQkzAgYAAAwYJeEGSUJAADgFhkGAAAMSDCYETAAAGBAScKMgAEAAAMCBjPWMAAAALfIMAAAYECCwYyAAQAAA0oSZpQkAACAW2QYAAAwIMFgRsAAAIABJQkzShIAAMAtMgwAABiQYDAjYAAAwICShBklCQAA4BYZBgAADEgwmBEwAABgQEnCjIABAAAD4gUz1jAAAAC3CBgAADCwWCxeuzyVnZ2tsLAwBQQEKDIyUhs3bjxj302bNik+Pl7t27dX69atFR4erjlz5pj6LV++XBEREbJarYqIiNCKFSs8nhcBAwAABhaL9y5P5ObmKi0tTZmZmSoqKtKgQYOUmJiokpKSBvsHBgZqwoQJ2rBhg7766itNmjRJkyZN0uLFi519CgoKlJycrJSUFG3dulUpKSkaNWqUtmzZ4tl34nA4HJ59nKbRuv+E5p4C0OIc/nhBc08BaJECmngFXtyTG7w2Vv7vBze6b3R0tAYMGKBFixY523r16qWkpCRlZWU1aoyRI0cqMDBQr7zyiiQpOTlZVVVVWrt2rbPPsGHD1LZtW+Xk5DR6bmQYAAAw8GZJwm63q6qqyuWy2+2m96ypqVFhYaESEhJc2hMSEpSfn9+oeRcVFSk/P19XXXWVs62goMA05vXXX9/oMX9AwAAAgIE3SxJZWVkKCgpyuRrKFlRWVqqurk42m82l3Wazqby8/Kzz7dKli6xWq6KiojR+/HiNHTvWea+8vPycxjRiWyUAAE0oIyND6enpLm1Wq/WM/Y0LJR0Oh9vFkxs3blR1dbU2b96sRx99VN27d9dtt932o8Y0ImAAAMDAmwc3Wa3WswYIPwgODpavr6/pN/+KigpThsAoLCxMknTZZZdp//79mjZtmjNg6NSp0zmNaURJAgAAg+bYVunv76/IyEjl5eW5tOfl5SkuLq7R4zgcDpc1ErGxsaYx161b59GYEhkGAABajPT0dKWkpCgqKkqxsbFavHixSkpKlJqaKul0eaO0tFTLli2TJC1cuFBdu3ZVeHi4pNPnMjz99NN68MEHnWNOnDhRgwcP1uzZszVixAitWrVK69ev16ZNmzyaGwEDAAAGzXU0dHJysg4ePKgZM2aorKxMffr00Zo1axQaGipJKisrczmTob6+XhkZGdq1a5f8/PzUrVs3zZo1S/fdd5+zT1xcnF5//XVNmjRJkydPVrdu3ZSbm6vo6GiP5sY5DEALxjkMQMOa+hyGq+d6tuXwbD5M8yz131KRYQAAwICHT5mx6BEAALhFhgEAAANvbqv8qSBgAADAgHjBjJIEAABwiwwDAAAGPqQYTAgYAAAwIF4woyQBAADcIsMAAIABuyTMCBgAADDwIV4wIWAAAMCADIMZaxgAAIBbZBgAADAgwWBGwAAAgIFFRAxGlCQAAIBbZBgAADBgl4QZAQMAAAbskjCjJAEAANwiwwAAgAEJBjMCBgAADHhapRklCQAA4BYZBgAADEgwmBEwAABgwC4JMwIGAAAMiBfMWMMAAADcIsMAAIABuyTMCBgAADAgXDCjJAEAANwiwwAAgAG7JMwIGAAAMOBplWaUJAAAgFtkGAAAMKAkYUbAAACAAfGCGSUJAADgFhkGAAAMKEmYETAAAGDALgkzAgYAAAzIMJixhgEAALhFhgEAAAPyC2YEDAAAGPC0SjNKEgAAwC0yDAAAGJBgMCNgAADAgF0SZpQkAACAWwQMAAAYWCzeuzyVnZ2tsLAwBQQEKDIyUhs3bjxj37feektDhw5Vhw4d1KZNG8XGxuq9995z6bN06VJZLBbTdfLkSY/mRcAAAICBj8XitcsTubm5SktLU2ZmpoqKijRo0CAlJiaqpKSkwf4bNmzQ0KFDtWbNGhUWFuqaa67R8OHDVVRU5NKvTZs2Kisrc7kCAgI8mhtrGAAAaCGeffZZjRkzRmPHjpUkzZ07V++9954WLVqkrKwsU/+5c+e6/Dxz5kytWrVKf/vb39S/f39nu8ViUadOnX7U3MgwAABg4M2ShN1uV1VVlctlt9tN71lTU6PCwkIlJCS4tCckJCg/P79R866vr9exY8fUrl07l/bq6mqFhoaqS5cuuvHGG00ZiMYgYAAAwKChmv+5XllZWQoKCnK5GsoWVFZWqq6uTjabzaXdZrOpvLy8UfN+5plndPz4cY0aNcrZFh4erqVLl2r16tXKyclRQECA4uPjtX37do++kxZTkvhi3dPNPQWgxWk7clFzTwFokU6svr9Jx/fmb9MZGRlKT093abNarWfsb9zS6XA4GrXNMycnR9OmTdOqVavUsWNHZ3tMTIxiYmKcP8fHx2vAgAGaP3++5s2b19iP0XICBgAAfoqsVutZA4QfBAcHy9fX15RNqKioMGUdjHJzczVmzBi98cYbuu66687a18fHRwMHDvQ4w0BJAgAAA2+WJBrL399fkZGRysvLc2nPy8tTXFzcGV+Xk5Oju+++W6+99ppuuOEGt+/jcDhUXFyszp07N3puEhkGAABMfJrpoMf09HSlpKQoKipKsbGxWrx4sUpKSpSamirpdHmjtLRUy5Ytk3Q6WBg9erSee+45xcTEOLMTrVu3VlBQkCRp+vTpiomJUY8ePVRVVaV58+apuLhYCxcu9GhuBAwAALQQycnJOnjwoGbMmKGysjL16dNHa9asUWhoqCSprKzM5UyG559/XrW1tRo/frzGjx/vbL/rrru0dOlSSdKRI0c0btw4lZeXKygoSP3799eGDRt0xRVXeDQ3i8PhcPz4j/jj7Tzg2YlTwM9B7zFLmnsKQIvU1Ise01d/7bWxnr0p3GtjNScyDAAAGPDwKTMWPQIAALfIMAAAYNBcix5bMgIGAAAMqEiYUZIAAABukWEAAMDA08dS/xwQMAAAYED63YyAAQAAAxIMZgRRAADALTIMAAAYsIbBjIABAAAD4gUzShIAAMAtMgwAABhw0qMZAQMAAAasYTCjJAEAANwiwwAAgAEJBjMCBgAADFjDYEZJAgAAuEWGAQAAA4tIMRgRMAAAYEBJwoyAAQAAAwIGM9YwAAAAt8gwAABgYGFfpQkBAwAABpQkzChJAAAAt8gwAABgQEXCjIABAAADHj5lRkkCAAC4RYYBAAADFj2aETAAAGBARcKMkgQAAHCLDAMAAAY+PHzKhIABAAADShJmBAwAABiw6NGMNQwAAMAtMgwAABhwcJMZAQMAAAbEC2aUJAAAgFtkGAAAMKAkYUbAAACAAfGCGSUJAADgFhkGAAAM+G3ajIABAAADCzUJE4IoAABakOzsbIWFhSkgIECRkZHauHHjGfu+9dZbGjp0qDp06KA2bdooNjZW7733nqnf8uXLFRERIavVqoiICK1YscLjeREwAABgYPHi5Ync3FylpaUpMzNTRUVFGjRokBITE1VSUtJg/w0bNmjo0KFas2aNCgsLdc0112j48OEqKipy9ikoKFBycrJSUlK0detWpaSkaNSoUdqyZYtHc7M4HA6Hh5+nSew8cLK5pwC0OL3HLGnuKQAt0onV9zfp+H8p3Ou1se6M7NLovtHR0RowYIAWLVrkbOvVq5eSkpKUlZXVqDF69+6t5ORkTZkyRZKUnJysqqoqrV271tln2LBhatu2rXJycho9NzIMAAAYNEeGoaamRoWFhUpISHBpT0hIUH5+fqPGqK+v17Fjx9SuXTtnW0FBgWnM66+/vtFj/oBFjwAANCG73S673e7SZrVaZbVaXdoqKytVV1cnm83m0m6z2VReXt6o93rmmWd0/PhxjRo1ytlWXl7+o8b8ARkGAAAMLBbvXVlZWQoKCnK5zlZeMO7QcDgcjdq1kZOTo2nTpik3N1cdO3b0ypj/jQwDAAAG3txWmZGRofT0dJc2Y3ZBkoKDg+Xr62v6zb+iosKUITDKzc3VmDFj9MYbb+i6665zudepU6dzGtOIDAMAAE3IarWqTZs2LldDAYO/v78iIyOVl5fn0p6Xl6e4uLgzjp+Tk6O7775br732mm644QbT/djYWNOY69atO+uYDSHDAACAQXP9Np2enq6UlBRFRUUpNjZWixcvVklJiVJTUyWdzlaUlpZq2bJlkk4HC6NHj9Zzzz2nmJgYZyahdevWCgoKkiRNnDhRgwcP1uzZszVixAitWrVK69ev16ZNmzyaGxkGAAAMLBaL1y5PJCcna+7cuZoxY4b69eunDRs2aM2aNQoNDZUklZWVuZzJ8Pzzz6u2tlbjx49X586dndfEiROdfeLi4vT6669ryZIluvzyy7V06VLl5uYqOjras++EcxiAlotzGICGNfU5DH8t3ue1sUb1u8hrYzUnShIAABjwJAkzAgYAAAx4+JQZaxgAAIBbZBgAADDgt2kzAgYAAAwoSZgRMAAAYEC4YEbWBQAAuEWGAQAAAyoSZgQMAAAY+FCUMKEkAQAA3CLDAACAASUJMwIGAAAMLJQkTChJAAAAt8gwAABgQEnCjIABAAADdkmYUZIAAABukWEAAMCAkoQZAQMAAAYEDGYEDAAAGLCt0ow1DAAAwC0yDAAAGPiQYDAhYAAAwICShBklCQAA4BYZBgAADNglYUbAAACAASUJM0oSAADALTIMAAAYsEvCjIDhf8znxYV687Wl2vHNVzp08IAmz5yjuMFDJEm1taf08uIF+mTzJpXt26vAwAvUPypav7l/otoHdzzjmB/9Y71yl72kfaV7VFt7Shd3CdXIW1N07bDhzj51tbX6y5//pA/y3tHhgwfVrn2wrvvlTbrtrnHy8TmdqHrztZe1PGepJGnUnffoV8kpztd//cVnWvjMTM194VX5+vo2wTeDn7N7E3vr3sTeCu14gSTpq5JDmvl6odZ9WiJJOrH6/gZf98clBZqzorjBe36+Pnrk1/1155Ceuqh9oL4tPaJJL29W3qd7Guz/8K/767HRMVqw+jM98uJHzva0pL5KG9lPkvTMm0Wav/oz572Bv+iouamDNejh5aqvd3j6sdGEKEmYETD8jzl54oQu7d5TCTeM0OOZv3O5Zz95Ut99+7Vuu2ucLu3RU8eqqvT8vCc1/Q8TNe+lnDOOecEFQUoePVYhoWHya9VK//xog57NmqoL27ZTZHS8JOmvry7RmlVv6HeZjyk0rJu+/fpLzZk5RYGBFyhp1B3a9d12/eWlbE17cp4cDmna7x9U/4ExuuTSHqqtPaX5Tz+u3/5+CsECmkRpZbUmv7xZ35UdlSTdOaSn3sgcppi0N/TVnsO6ZPRSl/4JkV31pwev0Yr878445rQ7r9BtV/fQAwv+oW/2HtbQAV2VmzFM1/xhhbburHTpG9m9g8ZcH6HPdrm29w5tp8l3DNTIx9bKIumtyb/U+8V79WXJIfn5+mjeA4M1YcE/CBbwP4GA4X/MwNgrNTD2ygbvBZ5/gWbOfd6l7f6HHlXavXeoorxMHTt1bvB1lw8Y6PJz0qg7tP7d1frisyJnwPD1F1sVc+XVuiJusCTJ1vli/WP9Wm3/5gtJ0p7dO3VJtx7qFxktSQrr1kN7du/SJZf20JuvvazL+kaqZ68+5/7BgbNY8/H3Lj9P+8s/dW9ib10RbtNXew5r/5ETLveHR4fpH5+Xavf+Y2cc8/arf6HZbxTqvcLTWYoX1n6hof1DNDGpr+559n1nv8AAPy353XV6YMGHenRUpMsY4V3aatvuQ/rHZ6WSpG27Dyo85EJ9WXJID43sp4+2lalwx4Ef9dnRNNglYcaix5+4f1VXy2KxKPCCCxrV3+FwqOiTLdpbslt9+v3nL7/el/VXceE/tbdktyRp5/Zv9MVnRRoYM0iSdEm3Hird870qysu0v3yfSvd8r9BLu2vf3hKtX7NKo8dN8PpnAxri42PRLYO6KzCglbZ8vd90v+OFrTUsqqtezvv6rOP4t/LVyVN1Lm0namoV16uTS9vc1MF695Pv9cHWUtMY274/qO4XBSkk+Hx17XC+ul98ob74/pAu7dxGKUN6atqr/zyHT4j/DxYvXj8VZBh+wmrsdi3503O6emiiAgPPP2vf49XHdOevhupUzSn5+PpofPofNWBgrPP+LXfeo+PHqzXujiT5+Piqvr5Od417UFcPTZQkdb3kUt1934P640P3SZLuTv2tul5yqTImjtM9Dzykwi35evXPi+Tr56fUiX/QZf0iG5wHcK56h7bTh0+OVIC/r6pPnFLyzHf19Z7Dpn53DumpYydOaWXBzrOOt75oj347oq82bSvTzvKjuqZvF90YfYl8ff7ze9Ytg7qr36XBuvJ3yxsc45u9RzT1lS16e8bp9UBTlm3WN3uP6J0Zw5W5tEBD+4co87aBOlVXp4df+EgffVH2I74BeJMPKQYTrwcMe/bs0dSpU/XnP//5jH3sdrvsdruhzSGr1ert6fxs1dae0qxpf1C9o17jf5fptn/r8wK1cMlfdeLEv1T8yRa9sOAZdb6oi7Nc8Y/339Xf172j30/NUmhYd+3c/rWen/eU2gV30NDEmyRJNySN0g1Jo5xj5q1Zpdbnnadeffrq3ttH6LkXXlXlgf2aNfUPWvLGGvn7+zfNh8fP0relRxSd9lddGGhVUtyleiFtiBL+uMoUNIy+Lly5/9guuyF7YPTwC5uUPeFqbc2+VQ5JO8uqtGz9Nxp9XU9JUpfgQD11b7yGT3n7rGO9+O6XevHdL50/3zmkp6pP1GjLN/u1Nfs2Xfm75bo4OFCvPDxU4ff+RTW19ef+JQBNyOsBw6FDh/Tyyy+fNWDIysrS9OnTXdp++3CmJv5+kren87NUW3tKMyc/ovJ9pZo17wW32QVJ8vHx0UVdukqSuvUI157vdyn3Ly85A4aXsudo1B336OrrTmcUwrr1UEV5mf76ykvOgOG/HT1yWK8teV5PLlyib778XBeHdNXFIaG6OCRUtXW1Kt3zvcK69fDip8bP3anaeu0sq5IkfbrjgCK7d9T44ZfpwewNzj7xEZ3Vs0tbpTyZ53a8yqqTGjXzXVlb+ar9BQHad+i4Hr8rxrnuoX+3DrJdeJ7y5/za+Ro/Xx9d2fsipd7QR0E3LzYtZmx/QYD+eGuUhmas1MBf2LRj3xF9V3ZU35UdlZ+fj3r8u2SB5kd+wczjgGH16tVnvb9z59nTfJKUkZGh9PR0l7bSKlYJe8MPwcK+vSWaNe9FtQm68JzGcTgcOlVzyvmz/eRJWXxcl7z4+PrKUd/wb0PPz3tSScl3qkNHm779aptqa2ud9+pra1Vff/bf7oAfy2KRrK1cd+XcNTRchdsr9Pnug40ex36qTvsOHZefr4+S4i7V8k2nd1Z88FmpIifkuvRdPPEafbP3sJ5ZXtzgzoen7o3X/FVbVXrwuCJ7dJSf33/+TPn5+siXzf8tB/8pTDwOGJKSkmSxWORwnPl/8BY3tR+r1WoqP1TaT3o6lZ+lE//6l/aVljh/3l9Wqu+2f60LLghS++AOemLSw9rx7VeaPnu+6uvrdejg6W1eF7QJUqtWrSRJTz+WqfYdOuo3qRMlSbmvvKQe4RHqfFGIamtP6eOCjXr/3bc14eH/lDKi46/S68teUEdbJ4WGddOOb7/WW7mvKOGXI0xz/PTjAu3bU6KHJz0hSeoZ0Ud7v9+tjws26UBFuXx8fdWl6yVN9RXhZ2h6SrTWFZZoT2W1LmjdSrcM6q7BfS7STdPfcfa5oHUrjYzvpkf/nN/gGC+mDdG+Q8c1ZdkWSafPSLiofaC27qzUxe3PV+ZtUfKxWPTsW0WSpOoTp/RliWs24PjJUzp0zG5ql6Qh/bqoe+cgjZlzeofFJ99WqOfFbZUwoKu6dAhUXX29vi094o2vA2gSHgcMnTt31sKFC5WUlNTg/eLiYkVGsqCtqWz/+gv94bdjnT8vnv+0JOm6xJt05z2p2rzpQ0nS+N+Mcnnd7HkvOssLFfvLXbIFJ0+c0MJnZqqyYr/8rVaFhIbpkSlP6Kprhzn73P/Qo1r2wkItfGamjhw+pHbBHfTLm36t239zn8v72O0nlf1sljJmPOk80Cm4g033P/So5mRNUatW/vpd5mOyWgO896XgZ6/jha310kND1KldoI4er9G23Qd10/R39Pfivc4+twzuLotF+uuGHQ2OEdLhfNX/1y9C1la+mnrHFQrr1EbVJ0/pvU9KNGbO+zp6vMbj+QX4+2rOuEFKeWqdfniLfYeOK33xJj0/8RrVnKrTvXP/rpM1ZN5aCg5uMrM4zpYqaMBNN92kfv36acaMGQ3e37p1q/r376/6M6Sqz2TnATIMgFHvMUuaewpAi3Sm0zu95Z87j3ptrCsuDfLaWM3J4wzDI488ouPHj5/xfvfu3fXBBx/8qEkBAICWxeOAYdCgQWe9HxgYqKuuuuqcJwQAQHOjIGHGwU0AABgRMZhwNDQAAHCLDAMAAAbskjAjYAAAwIBHSZhRkgAAwKA5n1aZnZ2tsLAwBQQEKDIyUhs3bjxj37KyMt1+++3q2bOnfHx8lJaWZuqzdOlSWSwW03XypGfHGRAwAADQQuTm5iotLU2ZmZkqKirSoEGDlJiYqJKSkgb72+12dejQQZmZmerbt+8Zx23Tpo3KyspcroAAzw7QI2AAAMComVIMzz77rMaMGaOxY8eqV69emjt3rkJCQrRo0aIG+19yySV67rnnNHr0aAUFnfmAKIvFok6dOrlcniJgAADAwOLFf+x2u6qqqlwuu91ues+amhoVFhYqISHBpT0hIUH5+Q0/A6WxqqurFRoaqi5duujGG29UUVGRx2MQMAAA0ISysrIUFBTkcmVlZZn6VVZWqq6uTjabzaXdZrOpvLz8nN8/PDxcS5cu1erVq5WTk6OAgADFx8dr+/btHo3DLgkAAAy8uUsiIyND6enpLm3GJza7vrfrmzscDrdPgT6bmJgYxcTEOH+Oj4/XgAEDNH/+fM2bN6/R4xAwAABg4M1dlVar9awBwg+Cg4Pl6+tryiZUVFSYsg4/ho+PjwYOHOhxhoGSBAAALYC/v78iIyOVl5fn0p6Xl6e4uDivvY/D4VBxcbE6d+7s0evIMAAAYNRMBzelp6crJSVFUVFRio2N1eLFi1VSUqLU1FRJp8sbpaWlWrZsmfM1xcXFkk4vbDxw4ICKi4vl7++viIgISdL06dMVExOjHj16qKqqSvPmzVNxcbEWLlzo0dwIGAAAMGiuo6GTk5N18OBBzZgxQ2VlZerTp4/WrFmj0NBQSacPajKeydC/f3/nvxcWFuq1115TaGiodu/eLUk6cuSIxo0bp/LycgUFBal///7asGGDrrjiCo/mZnE4HI4f9/G8Y+cBz06cAn4Oeo9Z0txTAFqkE6vvb9LxP9tT7bWxLg8532tjNScyDAAAGPAsCTMCBgAADIgXzAgYAAAwImIwYVslAABwiwwDAAAGzbVLoiUjYAAAwIBFj2aUJAAAgFtkGAAAMCDBYEbAAACAERGDCSUJAADgFhkGAAAM2CVhRsAAAIABuyTMKEkAAAC3yDAAAGBAgsGMgAEAACMiBhMCBgAADFj0aMYaBgAA4BYZBgAADNglYUbAAACAAfGCGSUJAADgFhkGAACMSDGYEDAAAGDALgkzShIAAMAtMgwAABiwS8KMgAEAAAPiBTNKEgAAwC0yDAAAGJFiMCFgAADAgF0SZgQMAAAYsOjRjDUMAADALTIMAAAYkGAwI2AAAMCAkoQZJQkAAOAWGQYAAExIMRgRMAAAYEBJwoySBAAAcIsMAwAABiQYzAgYAAAwoCRhRkkCAAC4RYYBAAADniVhRsAAAIAR8YIJAQMAAAbEC2asYQAAAG6RYQAAwIBdEmZkGAAAMLB48R9PZWdnKywsTAEBAYqMjNTGjRvP2LesrEy33367evbsKR8fH6WlpTXYb/ny5YqIiJDValVERIRWrFjh8bwIGAAAaCFyc3OVlpamzMxMFRUVadCgQUpMTFRJSUmD/e12uzp06KDMzEz17du3wT4FBQVKTk5WSkqKtm7dqpSUFI0aNUpbtmzxaG4Wh8Ph8PgTNYGdB0429xSAFqf3mCXNPQWgRTqx+v4mHf9Ada3XxupwfuOr/9HR0RowYIAWLVrkbOvVq5eSkpKUlZV11tdeffXV6tevn+bOnevSnpycrKqqKq1du9bZNmzYMLVt21Y5OTmNnhsZBgAADCxevOx2u6qqqlwuu91ues+amhoVFhYqISHBpT0hIUH5+fnn/FkKCgpMY15//fUej0nAAABAE8rKylJQUJDL1VC2oLKyUnV1dbLZbC7tNptN5eXl5/z+5eXlXhmTXRIAABh4c5dERkaG0tPTXdqsVutZ3tv1zR0Oh6nNU94Yk4ABAAADbx4NbbVazxog/CA4OFi+vr6m3/wrKipMGQJPdOrUyStjUpIAAKAF8Pf3V2RkpPLy8lza8/LyFBcXd87jxsbGmsZct26dx2OSYQAAwKC5Dm5KT09XSkqKoqKiFBsbq8WLF6ukpESpqamSTpc3SktLtWzZMudriouLJUnV1dU6cOCAiouL5e/vr4iICEnSxIkTNXjwYM2ePVsjRozQqlWrtH79em3atMmjuREwAADQQiQnJ+vgwYOaMWOGysrK1KdPH61Zs0ahoaGSTh/UZDyToX///s5/Lyws1GuvvabQ0FDt3r1bkhQXF6fXX39dkyZN0uTJk9WtWzfl5uYqOjrao7lxDgPQgnEOA9Cwpj6H4ciJOq+NdWFrX6+N1ZxYwwAAANyiJAEAgIE3d0n8VBAwAABgwNMqzShJAAAAt8gwAABgQILBjIABAAAjIgYTShIAAMAtMgwAABiwS8KMgAEAAAN2SZhRkgAAAG6RYQAAwIAEgxkBAwAARkQMJgQMAAAYsOjRjDUMAADALTIMAAAYsEvCzOJwOBzNPQm0HHa7XVlZWcrIyJDVam3u6QAtAn8uAAIGGFRVVSkoKEhHjx5VmzZtmns6QIvAnwuANQwAAKARCBgAAIBbBAwAAMAtAga4sFqtmjp1Kgu7gP/CnwuARY8AAKARyDAAAAC3CBgAAIBbBAwAAMAtAgYAAOAWAQOcsrOzFRYWpoCAAEVGRmrjxo3NPSWgWW3YsEHDhw/XRRddJIvFopUrVzb3lIBmQ8AASVJubq7S0tKUmZmpoqIiDRo0SImJiSopKWnuqQHN5vjx4+rbt68WLFjQ3FMBmh3bKiFJio6O1oABA7Ro0SJnW69evZSUlKSsrKxmnBnQMlgsFq1YsUJJSUnNPRWgWZBhgGpqalRYWKiEhASX9oSEBOXn5zfTrAAALQkBA1RZWam6ujrZbDaXdpvNpvLy8maaFQCgJSFggJPFYnH52eFwmNoAAD9PBAxQcHCwfH19TdmEiooKU9YBAPDzRMAA+fv7KzIyUnl5eS7teXl5iouLa6ZZAQBaEr/mngBahvT0dKWkpCgqKkqxsbFavHixSkpKlJqa2txTA5pNdXW1duzY4fx5165dKi4uVrt27dS1a9dmnBnw/49tlXDKzs7Wk08+qbKyMvXp00dz5szR4MGDm3taQLP58MMPdc0115ja77rrLi1duvT/f0JAMyJgAAAAbrGGAQAAuEXAAAAA3CJgAAAAbhEwAAAAtwgYAACAWwQMAADALQIGAADgFgEDAABwi4ABAAC4RcAAAADcImAAAABuETAAAAC3/g/x90ie3m3SqgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, LSTM, Dropout, Input, concatenate\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "# First branch for the LSTM\n",
    "lstm_input = Input(shape=(1, 100))\n",
    "lstm_output = LSTM(units=256, return_sequences=True, activation='relu')(lstm_input)\n",
    "lstm_output = Dropout(0.2)(lstm_output)\n",
    "lstm_output = LSTM(units=256, return_sequences=True, activation='relu')(lstm_output)\n",
    "lstm_output = Dropout(0.2)(lstm_output)\n",
    "lstm_output = LSTM(units=128, return_sequences=True, activation='relu')(lstm_output)\n",
    "lstm_output = Dropout(0.2)(lstm_output)\n",
    "lstm_output = LSTM(units=64, activation='relu')(lstm_output)\n",
    "lstm_output = Dropout(0.2)(lstm_output)\n",
    "\n",
    "# Second branch for the dense layers\n",
    "dense_input = Input(shape=(5,))\n",
    "dense_output = Dense(units=64, activation='relu')(dense_input)\n",
    "dense_output = Dropout(0.2)(dense_output)\n",
    "dense_output = Dense(units=32, activation='relu')(dense_output)\n",
    "dense_output = Dropout(0.2)(dense_output)\n",
    "\n",
    "# Concatenate the outputs from both branches\n",
    "combined = concatenate([lstm_output, dense_output])\n",
    "\n",
    "combined = Dense(units = 64, activation='relu')(combined)\n",
    "\n",
    "# Final output layer\n",
    "output = Dense(units=1, activation='sigmoid')(combined)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=[lstm_input, dense_input], outputs=output)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', 'AUC'])\n",
    "\n",
    "# Define the early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model with both LSTM and dense input\n",
    "model.fit([X_train_vec, X_train], y_train, epochs=100, batch_size=32,\n",
    "          validation_data=([X_test_vec, X_test], y_test),\n",
    "          callbacks=[early_stopping])\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict([X_test_vec, X_test])\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "y_pred_class = (y_pred > .5).astype(int)\n",
    "accuracy = accuracy_score(y_test,y_pred_class)\n",
    "print('ROC-AUC:', roc_auc)\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "matrix = confusion_matrix(y_test, y_pred_class)\n",
    "\n",
    "sns.heatmap(matrix/np.sum(matrix), annot=True, fmt='.2%', cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59dc53ff-9c21-466a-8e9f-f10b3833b0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model containing character length, number of capital words, upvotes and # of comments\n",
    "#Model 2 adds POS tagging and standard scaling of variables\n",
    "#Only left in proper nouns as others decreased performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77a3b55f-1112-4739-b2cf-337ce0205e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "#create extra variables for later\n",
    "df_other_var = create_other_var(df)\n",
    "\n",
    "#Create simple dataframe with only text and predictor\n",
    "df = df[['Title','Political Lean']] \n",
    "\n",
    "#dummy code predictor\n",
    "df['Political Lean'] = df['Political Lean'].replace('Liberal',1)\n",
    "df['Political Lean'] = df['Political Lean'].replace('Conservative',0)\n",
    "\n",
    "df = df.rename({'Political Lean':'y'},axis=1) #replace column name for simplicity\n",
    "\n",
    "df = pd.concat([df,df_other_var],axis=1)\n",
    "\n",
    "df = df[df['Length']>=15]\n",
    "\n",
    "#Split into X & y\n",
    "X = df.drop(['y'],axis=1)\n",
    "y = df['y']\n",
    "\n",
    "#oversample minority class\n",
    "oversample = RandomOverSampler(sampling_strategy='minority', random_state=13)\n",
    "X, y = oversample.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eed9495c-923f-474f-9f74-dd19b9ac4074",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'merge'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m loss_df \u001b[38;5;241m=\u001b[39m \u001b[43mX_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m(X[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTitle\u001b[39m\u001b[38;5;124m'\u001b[39m]],left_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,right_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m loss_df \u001b[38;5;241m=\u001b[39m loss_df\u001b[38;5;241m.\u001b[39mmerge(y,left_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,right_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m predictions \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(y_pred, columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprob\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'merge'"
     ]
    }
   ],
   "source": [
    "loss_df = X_test.merge(X[['Title']],left_index=True,right_index=True,how='left')\n",
    "loss_df = loss_df.merge(y,left_index=True,right_index=True,how='left')\n",
    "predictions = pd.DataFrame(y_pred, columns = ['prob'])\n",
    "loss_df = pd.concat([loss_df,predictions.set_index(loss_df.index)],axis=1)\n",
    "loss_df['prob'] = abs(loss_df['prob']-.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83928af4-ce6f-427f-89a2-874bc4d50d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_df.sort_values(by='prob').head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ea316a-dd0e-403b-941b-a187813ce181",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LHL_env",
   "language": "python",
   "name": "lhl_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
