{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67233b73-f1a2-4cab-a395-0acf30fb4ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Andrew\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Andrew\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "df = pd.read_csv(\"../data/fulldata.csv\")\n",
    "df2 = pd.read_csv(\"../data/6_14_pull.csv\")\n",
    "\n",
    "df = pd.concat([df,df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a16c2532-c2f2-48f7-84f6-7f9e0049ea0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Cleaning import lowercase, unpunctuate, tokenize, lemmatize, count_capitalized_words, create_other_var, cleaning_and_prep, stack_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb47f54a-ec57-4308-a10d-62853364b7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andrew\\Documents\\LHL\\PoliticalNLP\\python\\Cleaning.py:127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Political Lean'] = df['Political Lean'].replace('Liberal',1)\n",
      "C:\\Users\\Andrew\\Documents\\LHL\\PoliticalNLP\\python\\Cleaning.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Political Lean'] = df['Political Lean'].replace('Conservative',0)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = cleaning_and_prep(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c07ff43-bee3-4c11-9e29-29c25764a85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vec, X_test_vec, X_train, X_test = stack_vectors(X_train,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83645586-d576-4de0-ae1e-d3897c0b206b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "763/763 [==============================] - 6s 6ms/step - loss: 0.6569 - accuracy: 0.6127 - auc: 0.6624 - val_loss: 0.6240 - val_accuracy: 0.6462 - val_auc: 0.7171\n",
      "Epoch 2/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.6251 - accuracy: 0.6478 - auc: 0.7070 - val_loss: 0.6064 - val_accuracy: 0.6643 - val_auc: 0.7378\n",
      "Epoch 3/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.6153 - accuracy: 0.6562 - auc: 0.7210 - val_loss: 0.5953 - val_accuracy: 0.6696 - val_auc: 0.7480\n",
      "Epoch 4/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.6076 - accuracy: 0.6645 - auc: 0.7318 - val_loss: 0.5872 - val_accuracy: 0.6747 - val_auc: 0.7595\n",
      "Epoch 5/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5997 - accuracy: 0.6673 - auc: 0.7393 - val_loss: 0.5802 - val_accuracy: 0.6856 - val_auc: 0.7656\n",
      "Epoch 6/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5935 - accuracy: 0.6727 - auc: 0.7455 - val_loss: 0.5746 - val_accuracy: 0.6912 - val_auc: 0.7739\n",
      "Epoch 7/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5879 - accuracy: 0.6748 - auc: 0.7517 - val_loss: 0.5688 - val_accuracy: 0.6986 - val_auc: 0.7780\n",
      "Epoch 8/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5816 - accuracy: 0.6830 - auc: 0.7593 - val_loss: 0.5635 - val_accuracy: 0.7028 - val_auc: 0.7824\n",
      "Epoch 9/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5781 - accuracy: 0.6848 - auc: 0.7620 - val_loss: 0.5580 - val_accuracy: 0.7054 - val_auc: 0.7878\n",
      "Epoch 10/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5751 - accuracy: 0.6890 - auc: 0.7651 - val_loss: 0.5544 - val_accuracy: 0.7012 - val_auc: 0.7901\n",
      "Epoch 11/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5717 - accuracy: 0.6889 - auc: 0.7686 - val_loss: 0.5528 - val_accuracy: 0.7040 - val_auc: 0.7922\n",
      "Epoch 12/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5667 - accuracy: 0.6952 - auc: 0.7744 - val_loss: 0.5518 - val_accuracy: 0.7160 - val_auc: 0.7945\n",
      "Epoch 13/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5653 - accuracy: 0.6980 - auc: 0.7750 - val_loss: 0.5482 - val_accuracy: 0.7093 - val_auc: 0.7973\n",
      "Epoch 14/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5624 - accuracy: 0.6965 - auc: 0.7775 - val_loss: 0.5448 - val_accuracy: 0.7165 - val_auc: 0.7983\n",
      "Epoch 15/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5605 - accuracy: 0.6991 - auc: 0.7785 - val_loss: 0.5439 - val_accuracy: 0.7170 - val_auc: 0.7990\n",
      "Epoch 16/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5575 - accuracy: 0.7008 - auc: 0.7818 - val_loss: 0.5423 - val_accuracy: 0.7242 - val_auc: 0.8018\n",
      "Epoch 17/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5562 - accuracy: 0.7042 - auc: 0.7835 - val_loss: 0.5430 - val_accuracy: 0.7107 - val_auc: 0.8029\n",
      "Epoch 18/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5544 - accuracy: 0.7036 - auc: 0.7853 - val_loss: 0.5375 - val_accuracy: 0.7228 - val_auc: 0.8051\n",
      "Epoch 19/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5504 - accuracy: 0.7070 - auc: 0.7889 - val_loss: 0.5363 - val_accuracy: 0.7277 - val_auc: 0.8066\n",
      "Epoch 20/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5507 - accuracy: 0.7067 - auc: 0.7883 - val_loss: 0.5392 - val_accuracy: 0.7242 - val_auc: 0.8054\n",
      "Epoch 21/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5486 - accuracy: 0.7087 - auc: 0.7904 - val_loss: 0.5335 - val_accuracy: 0.7251 - val_auc: 0.8079\n",
      "Epoch 22/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5484 - accuracy: 0.7083 - auc: 0.7903 - val_loss: 0.5334 - val_accuracy: 0.7195 - val_auc: 0.8077\n",
      "Epoch 23/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5464 - accuracy: 0.7101 - auc: 0.7926 - val_loss: 0.5309 - val_accuracy: 0.7251 - val_auc: 0.8103\n",
      "Epoch 24/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5446 - accuracy: 0.7127 - auc: 0.7941 - val_loss: 0.5338 - val_accuracy: 0.7267 - val_auc: 0.8091\n",
      "Epoch 25/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5437 - accuracy: 0.7126 - auc: 0.7950 - val_loss: 0.5292 - val_accuracy: 0.7274 - val_auc: 0.8109\n",
      "Epoch 26/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5426 - accuracy: 0.7173 - auc: 0.7963 - val_loss: 0.5300 - val_accuracy: 0.7307 - val_auc: 0.8108\n",
      "Epoch 27/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5392 - accuracy: 0.7181 - auc: 0.7986 - val_loss: 0.5289 - val_accuracy: 0.7321 - val_auc: 0.8129\n",
      "Epoch 28/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5394 - accuracy: 0.7168 - auc: 0.7988 - val_loss: 0.5290 - val_accuracy: 0.7258 - val_auc: 0.8134\n",
      "Epoch 29/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5373 - accuracy: 0.7177 - auc: 0.8012 - val_loss: 0.5280 - val_accuracy: 0.7344 - val_auc: 0.8128\n",
      "Epoch 30/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5342 - accuracy: 0.7193 - auc: 0.8032 - val_loss: 0.5254 - val_accuracy: 0.7288 - val_auc: 0.8135\n",
      "Epoch 31/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5349 - accuracy: 0.7178 - auc: 0.8031 - val_loss: 0.5243 - val_accuracy: 0.7342 - val_auc: 0.8157\n",
      "Epoch 32/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5336 - accuracy: 0.7195 - auc: 0.8036 - val_loss: 0.5240 - val_accuracy: 0.7353 - val_auc: 0.8156\n",
      "Epoch 33/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5320 - accuracy: 0.7229 - auc: 0.8059 - val_loss: 0.5284 - val_accuracy: 0.7369 - val_auc: 0.8158\n",
      "Epoch 34/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5332 - accuracy: 0.7209 - auc: 0.8043 - val_loss: 0.5264 - val_accuracy: 0.7344 - val_auc: 0.8168\n",
      "Epoch 35/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5305 - accuracy: 0.7241 - auc: 0.8065 - val_loss: 0.5215 - val_accuracy: 0.7349 - val_auc: 0.8175\n",
      "Epoch 36/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5283 - accuracy: 0.7272 - auc: 0.8088 - val_loss: 0.5263 - val_accuracy: 0.7367 - val_auc: 0.8174\n",
      "Epoch 37/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5292 - accuracy: 0.7260 - auc: 0.8080 - val_loss: 0.5205 - val_accuracy: 0.7390 - val_auc: 0.8190\n",
      "Epoch 38/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5273 - accuracy: 0.7273 - auc: 0.8097 - val_loss: 0.5195 - val_accuracy: 0.7425 - val_auc: 0.8189\n",
      "Epoch 39/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5267 - accuracy: 0.7271 - auc: 0.8099 - val_loss: 0.5185 - val_accuracy: 0.7372 - val_auc: 0.8187\n",
      "Epoch 40/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5268 - accuracy: 0.7260 - auc: 0.8099 - val_loss: 0.5182 - val_accuracy: 0.7372 - val_auc: 0.8196\n",
      "Epoch 41/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5260 - accuracy: 0.7277 - auc: 0.8101 - val_loss: 0.5207 - val_accuracy: 0.7318 - val_auc: 0.8197\n",
      "Epoch 42/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5242 - accuracy: 0.7293 - auc: 0.8126 - val_loss: 0.5179 - val_accuracy: 0.7397 - val_auc: 0.8196\n",
      "Epoch 43/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5223 - accuracy: 0.7307 - auc: 0.8138 - val_loss: 0.5163 - val_accuracy: 0.7423 - val_auc: 0.8214\n",
      "Epoch 44/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5227 - accuracy: 0.7290 - auc: 0.8129 - val_loss: 0.5163 - val_accuracy: 0.7411 - val_auc: 0.8216\n",
      "Epoch 45/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5209 - accuracy: 0.7306 - auc: 0.8152 - val_loss: 0.5154 - val_accuracy: 0.7351 - val_auc: 0.8230\n",
      "Epoch 46/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5205 - accuracy: 0.7341 - auc: 0.8154 - val_loss: 0.5148 - val_accuracy: 0.7492 - val_auc: 0.8237\n",
      "Epoch 47/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5188 - accuracy: 0.7325 - auc: 0.8168 - val_loss: 0.5153 - val_accuracy: 0.7407 - val_auc: 0.8230\n",
      "Epoch 48/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5175 - accuracy: 0.7346 - auc: 0.8175 - val_loss: 0.5115 - val_accuracy: 0.7460 - val_auc: 0.8262\n",
      "Epoch 49/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5170 - accuracy: 0.7351 - auc: 0.8179 - val_loss: 0.5269 - val_accuracy: 0.7337 - val_auc: 0.8237\n",
      "Epoch 50/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5167 - accuracy: 0.7351 - auc: 0.8187 - val_loss: 0.5111 - val_accuracy: 0.7432 - val_auc: 0.8245\n",
      "Epoch 51/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5158 - accuracy: 0.7328 - auc: 0.8191 - val_loss: 0.5141 - val_accuracy: 0.7467 - val_auc: 0.8262\n",
      "Epoch 52/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5153 - accuracy: 0.7342 - auc: 0.8189 - val_loss: 0.5091 - val_accuracy: 0.7458 - val_auc: 0.8269\n",
      "Epoch 53/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5139 - accuracy: 0.7361 - auc: 0.8207 - val_loss: 0.5090 - val_accuracy: 0.7451 - val_auc: 0.8277\n",
      "Epoch 54/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5119 - accuracy: 0.7386 - auc: 0.8229 - val_loss: 0.5103 - val_accuracy: 0.7409 - val_auc: 0.8272\n",
      "Epoch 55/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5137 - accuracy: 0.7357 - auc: 0.8207 - val_loss: 0.5085 - val_accuracy: 0.7458 - val_auc: 0.8277\n",
      "Epoch 56/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5102 - accuracy: 0.7386 - auc: 0.8235 - val_loss: 0.5062 - val_accuracy: 0.7506 - val_auc: 0.8296\n",
      "Epoch 57/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5104 - accuracy: 0.7362 - auc: 0.8230 - val_loss: 0.5081 - val_accuracy: 0.7506 - val_auc: 0.8303\n",
      "Epoch 58/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5087 - accuracy: 0.7406 - auc: 0.8250 - val_loss: 0.5043 - val_accuracy: 0.7499 - val_auc: 0.8307\n",
      "Epoch 59/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5096 - accuracy: 0.7394 - auc: 0.8243 - val_loss: 0.5060 - val_accuracy: 0.7472 - val_auc: 0.8305\n",
      "Epoch 60/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5090 - accuracy: 0.7404 - auc: 0.8252 - val_loss: 0.5042 - val_accuracy: 0.7490 - val_auc: 0.8307\n",
      "Epoch 61/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5061 - accuracy: 0.7386 - auc: 0.8270 - val_loss: 0.5055 - val_accuracy: 0.7516 - val_auc: 0.8302\n",
      "Epoch 62/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5074 - accuracy: 0.7432 - auc: 0.8265 - val_loss: 0.5021 - val_accuracy: 0.7537 - val_auc: 0.8325\n",
      "Epoch 63/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5062 - accuracy: 0.7416 - auc: 0.8265 - val_loss: 0.5067 - val_accuracy: 0.7530 - val_auc: 0.8316\n",
      "Epoch 64/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5028 - accuracy: 0.7457 - auc: 0.8302 - val_loss: 0.5011 - val_accuracy: 0.7534 - val_auc: 0.8329\n",
      "Epoch 65/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5046 - accuracy: 0.7419 - auc: 0.8281 - val_loss: 0.5038 - val_accuracy: 0.7537 - val_auc: 0.8331\n",
      "Epoch 66/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5039 - accuracy: 0.7454 - auc: 0.8288 - val_loss: 0.5017 - val_accuracy: 0.7530 - val_auc: 0.8333\n",
      "Epoch 67/100\n",
      "763/763 [==============================] - 4s 6ms/step - loss: 0.5045 - accuracy: 0.7430 - auc: 0.8281 - val_loss: 0.4993 - val_accuracy: 0.7537 - val_auc: 0.8348\n",
      "Epoch 68/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5018 - accuracy: 0.7442 - auc: 0.8303 - val_loss: 0.4995 - val_accuracy: 0.7555 - val_auc: 0.8349\n",
      "Epoch 69/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5027 - accuracy: 0.7447 - auc: 0.8298 - val_loss: 0.5235 - val_accuracy: 0.7325 - val_auc: 0.8302\n",
      "Epoch 70/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5011 - accuracy: 0.7464 - auc: 0.8312 - val_loss: 0.5013 - val_accuracy: 0.7518 - val_auc: 0.8328\n",
      "Epoch 71/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5005 - accuracy: 0.7461 - auc: 0.8321 - val_loss: 0.4983 - val_accuracy: 0.7553 - val_auc: 0.8354\n",
      "Epoch 72/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.4983 - accuracy: 0.7473 - auc: 0.8333 - val_loss: 0.4969 - val_accuracy: 0.7550 - val_auc: 0.8361\n",
      "Epoch 73/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5001 - accuracy: 0.7480 - auc: 0.8323 - val_loss: 0.4975 - val_accuracy: 0.7509 - val_auc: 0.8363\n",
      "Epoch 74/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.4982 - accuracy: 0.7455 - auc: 0.8332 - val_loss: 0.4988 - val_accuracy: 0.7567 - val_auc: 0.8359\n",
      "Epoch 75/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.4955 - accuracy: 0.7486 - auc: 0.8353 - val_loss: 0.4977 - val_accuracy: 0.7564 - val_auc: 0.8368\n",
      "Epoch 76/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.4962 - accuracy: 0.7506 - auc: 0.8358 - val_loss: 0.5026 - val_accuracy: 0.7541 - val_auc: 0.8378\n",
      "Epoch 77/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.4941 - accuracy: 0.7504 - auc: 0.8364 - val_loss: 0.4941 - val_accuracy: 0.7562 - val_auc: 0.8388\n",
      "Epoch 78/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.4945 - accuracy: 0.7480 - auc: 0.8359 - val_loss: 0.4968 - val_accuracy: 0.7550 - val_auc: 0.8368\n",
      "Epoch 79/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.4932 - accuracy: 0.7507 - auc: 0.8370 - val_loss: 0.4950 - val_accuracy: 0.7560 - val_auc: 0.8381\n",
      "Epoch 80/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.4955 - accuracy: 0.7493 - auc: 0.8353 - val_loss: 0.4928 - val_accuracy: 0.7581 - val_auc: 0.8391\n",
      "Epoch 81/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.4919 - accuracy: 0.7503 - auc: 0.8377 - val_loss: 0.4926 - val_accuracy: 0.7609 - val_auc: 0.8391\n",
      "Epoch 82/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.4903 - accuracy: 0.7525 - auc: 0.8389 - val_loss: 0.4911 - val_accuracy: 0.7583 - val_auc: 0.8401\n",
      "Epoch 83/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.4915 - accuracy: 0.7500 - auc: 0.8380 - val_loss: 0.4953 - val_accuracy: 0.7606 - val_auc: 0.8391\n",
      "Epoch 84/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.4888 - accuracy: 0.7533 - auc: 0.8401 - val_loss: 0.4897 - val_accuracy: 0.7620 - val_auc: 0.8412\n",
      "Epoch 85/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.4893 - accuracy: 0.7538 - auc: 0.8402 - val_loss: 0.4985 - val_accuracy: 0.7567 - val_auc: 0.8396\n",
      "Epoch 86/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.4907 - accuracy: 0.7513 - auc: 0.8388 - val_loss: 0.4898 - val_accuracy: 0.7620 - val_auc: 0.8421\n",
      "Epoch 87/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.4877 - accuracy: 0.7542 - auc: 0.8409 - val_loss: 0.4903 - val_accuracy: 0.7618 - val_auc: 0.8415\n",
      "Epoch 88/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.4878 - accuracy: 0.7546 - auc: 0.8406 - val_loss: 0.4901 - val_accuracy: 0.7627 - val_auc: 0.8423\n",
      "Epoch 89/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.4867 - accuracy: 0.7548 - auc: 0.8419 - val_loss: 0.4920 - val_accuracy: 0.7595 - val_auc: 0.8408\n",
      "Epoch 90/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.4872 - accuracy: 0.7529 - auc: 0.8413 - val_loss: 0.4904 - val_accuracy: 0.7627 - val_auc: 0.8414\n",
      "Epoch 91/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.4856 - accuracy: 0.7555 - auc: 0.8423 - val_loss: 0.4910 - val_accuracy: 0.7525 - val_auc: 0.8436\n",
      "Epoch 92/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.4869 - accuracy: 0.7516 - auc: 0.8417 - val_loss: 0.4884 - val_accuracy: 0.7636 - val_auc: 0.8426\n",
      "Epoch 93/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.4847 - accuracy: 0.7572 - auc: 0.8436 - val_loss: 0.4873 - val_accuracy: 0.7602 - val_auc: 0.8436\n",
      "Epoch 94/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.4845 - accuracy: 0.7580 - auc: 0.8443 - val_loss: 0.4878 - val_accuracy: 0.7636 - val_auc: 0.8439\n",
      "Epoch 95/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.4820 - accuracy: 0.7568 - auc: 0.8457 - val_loss: 0.4865 - val_accuracy: 0.7595 - val_auc: 0.8444\n",
      "Epoch 96/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.4818 - accuracy: 0.7594 - auc: 0.8454 - val_loss: 0.4855 - val_accuracy: 0.7574 - val_auc: 0.8443\n",
      "Epoch 97/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.4815 - accuracy: 0.7572 - auc: 0.8457 - val_loss: 0.4854 - val_accuracy: 0.7653 - val_auc: 0.8448\n",
      "Epoch 98/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.4803 - accuracy: 0.7601 - auc: 0.8468 - val_loss: 0.4846 - val_accuracy: 0.7609 - val_auc: 0.8465\n",
      "Epoch 99/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.4822 - accuracy: 0.7607 - auc: 0.8451 - val_loss: 0.4849 - val_accuracy: 0.7604 - val_auc: 0.8454\n",
      "Epoch 100/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.4782 - accuracy: 0.7610 - auc: 0.8484 - val_loss: 0.4835 - val_accuracy: 0.7632 - val_auc: 0.8472\n",
      "135/135 [==============================] - 0s 2ms/step\n",
      "ROC-AUC: 0.8472269672421082\n",
      "Accuracy: 0.7631762247504064\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, LSTM, Dropout, Input, concatenate\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "# First branch for the LSTM\n",
    "lstm_input = Input(shape=(1, 100))\n",
    "lstm_output = LSTM(units=256, return_sequences=True, activation='relu')(lstm_input)\n",
    "lstm_output = Dropout(0.2)(lstm_output)\n",
    "lstm_output = LSTM(units=128, activation='relu')(lstm_output)\n",
    "lstm_output = Dropout(0.2)(lstm_output)\n",
    "\n",
    "# Second branch for the dense layers\n",
    "dense_input = Input(shape=(5,))\n",
    "dense_output = Dense(units=64, activation='relu')(dense_input)\n",
    "dense_output = Dropout(0.2)(dense_output)\n",
    "\n",
    "# Concatenate the outputs from both branches\n",
    "combined = concatenate([lstm_output, dense_output])\n",
    "\n",
    "combined = Dense(units = 64, activation='relu')(combined)\n",
    "\n",
    "# Final output layer\n",
    "output = Dense(units=1, activation='sigmoid')(combined)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=[lstm_input, dense_input], outputs=output)\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy', 'AUC'])\n",
    "\n",
    "# Define the early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model with both LSTM and dense input\n",
    "model.fit([X_train_vec, X_train], y_train, epochs=100, batch_size=32,\n",
    "          validation_data=([X_test_vec, X_test], y_test),\n",
    "          callbacks=[early_stopping])\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict([X_test_vec, X_test])\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "y_pred_class = (y_pred > .5).astype(int)\n",
    "accuracy = accuracy_score(y_test,y_pred_class)\n",
    "print('ROC-AUC:', roc_auc)\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "matrix = confusion_matrix(y_test, y_pred_class)\n",
    "\n",
    "sns.heatmap(matrix/np.sum(matrix), annot=True, fmt='.2%', cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59dc53ff-9c21-466a-8e9f-f10b3833b0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model containing character length, number of capital words, upvotes and # of comments\n",
    "#Model 2 adds POS tagging and standard scaling of variables\n",
    "#Only left in proper nouns as others decreased performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77a3b55f-1112-4739-b2cf-337ce0205e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "#create extra variables for later\n",
    "df_other_var = create_other_var(df)\n",
    "\n",
    "#Create simple dataframe with only text and predictor\n",
    "df = df[['Title','Political Lean']] \n",
    "\n",
    "#dummy code predictor\n",
    "df['Political Lean'] = df['Political Lean'].replace('Liberal',1)\n",
    "df['Political Lean'] = df['Political Lean'].replace('Conservative',0)\n",
    "\n",
    "df = df.rename({'Political Lean':'y'},axis=1) #replace column name for simplicity\n",
    "\n",
    "df = pd.concat([df,df_other_var],axis=1)\n",
    "\n",
    "df = df[df['Length']>=15]\n",
    "\n",
    "#Split into X & y\n",
    "X = df.drop(['y'],axis=1)\n",
    "y = df['y']\n",
    "\n",
    "#oversample minority class\n",
    "oversample = RandomOverSampler(sampling_strategy='minority', random_state=13)\n",
    "X, y = oversample.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eed9495c-923f-474f-9f74-dd19b9ac4074",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'merge'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m loss_df \u001b[38;5;241m=\u001b[39m \u001b[43mX_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m(X[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTitle\u001b[39m\u001b[38;5;124m'\u001b[39m]],left_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,right_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m loss_df \u001b[38;5;241m=\u001b[39m loss_df\u001b[38;5;241m.\u001b[39mmerge(y,left_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,right_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m predictions \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(y_pred, columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprob\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'merge'"
     ]
    }
   ],
   "source": [
    "loss_df = X_test.merge(X[['Title']],left_index=True,right_index=True,how='left')\n",
    "loss_df = loss_df.merge(y,left_index=True,right_index=True,how='left')\n",
    "predictions = pd.DataFrame(y_pred, columns = ['prob'])\n",
    "loss_df = pd.concat([loss_df,predictions.set_index(loss_df.index)],axis=1)\n",
    "loss_df['prob'] = abs(loss_df['prob']-.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83928af4-ce6f-427f-89a2-874bc4d50d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_df.sort_values(by='prob').head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ea316a-dd0e-403b-941b-a187813ce181",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LHL_env",
   "language": "python",
   "name": "lhl_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
