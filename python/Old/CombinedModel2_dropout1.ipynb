{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67233b73-f1a2-4cab-a395-0acf30fb4ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Andrew\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Andrew\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "df = pd.read_csv(\"../data/fulldata.csv\")\n",
    "df2 = pd.read_csv(\"../data/6_14_pull.csv\")\n",
    "\n",
    "df = pd.concat([df,df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a16c2532-c2f2-48f7-84f6-7f9e0049ea0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Cleaning import lowercase, unpunctuate, tokenize, lemmatize, count_capitalized_words, create_other_var, cleaning_and_prep, stack_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb47f54a-ec57-4308-a10d-62853364b7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andrew\\Documents\\LHL\\PoliticalNLP\\python\\Cleaning.py:127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Political Lean'] = df['Political Lean'].replace('Liberal',1)\n",
      "C:\\Users\\Andrew\\Documents\\LHL\\PoliticalNLP\\python\\Cleaning.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Political Lean'] = df['Political Lean'].replace('Conservative',0)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = cleaning_and_prep(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c07ff43-bee3-4c11-9e29-29c25764a85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vec, X_test_vec, X_train, X_test = stack_vectors(X_train,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83645586-d576-4de0-ae1e-d3897c0b206b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "763/763 [==============================] - 8s 7ms/step - loss: 0.6128 - accuracy: 0.6590 - auc: 0.7280 - val_loss: 0.5770 - val_accuracy: 0.6775 - val_auc: 0.7633\n",
      "Epoch 2/100\n",
      "763/763 [==============================] - 6s 8ms/step - loss: 0.5675 - accuracy: 0.6919 - auc: 0.7719 - val_loss: 0.5625 - val_accuracy: 0.6951 - val_auc: 0.7865\n",
      "Epoch 3/100\n",
      "763/763 [==============================] - 6s 7ms/step - loss: 0.5562 - accuracy: 0.7021 - auc: 0.7837 - val_loss: 0.5458 - val_accuracy: 0.7077 - val_auc: 0.7918\n",
      "Epoch 4/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.5475 - accuracy: 0.7121 - auc: 0.7928 - val_loss: 0.5473 - val_accuracy: 0.7047 - val_auc: 0.7948\n",
      "Epoch 5/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.5426 - accuracy: 0.7137 - auc: 0.7966 - val_loss: 0.5370 - val_accuracy: 0.7202 - val_auc: 0.8027\n",
      "Epoch 6/100\n",
      "763/763 [==============================] - 6s 8ms/step - loss: 0.5360 - accuracy: 0.7192 - auc: 0.8020 - val_loss: 0.5329 - val_accuracy: 0.7209 - val_auc: 0.8060\n",
      "Epoch 7/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.5336 - accuracy: 0.7232 - auc: 0.8052 - val_loss: 0.5270 - val_accuracy: 0.7272 - val_auc: 0.8110\n",
      "Epoch 8/100\n",
      "763/763 [==============================] - 6s 8ms/step - loss: 0.5256 - accuracy: 0.7268 - auc: 0.8106 - val_loss: 0.5257 - val_accuracy: 0.7258 - val_auc: 0.8104\n",
      "Epoch 9/100\n",
      "763/763 [==============================] - 6s 7ms/step - loss: 0.5238 - accuracy: 0.7312 - auc: 0.8141 - val_loss: 0.5213 - val_accuracy: 0.7316 - val_auc: 0.8155\n",
      "Epoch 10/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.5151 - accuracy: 0.7332 - auc: 0.8190 - val_loss: 0.5263 - val_accuracy: 0.7263 - val_auc: 0.8158\n",
      "Epoch 11/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.5139 - accuracy: 0.7356 - auc: 0.8207 - val_loss: 0.5138 - val_accuracy: 0.7414 - val_auc: 0.8226\n",
      "Epoch 12/100\n",
      "763/763 [==============================] - 6s 8ms/step - loss: 0.5075 - accuracy: 0.7419 - auc: 0.8260 - val_loss: 0.5126 - val_accuracy: 0.7397 - val_auc: 0.8239\n",
      "Epoch 13/100\n",
      "763/763 [==============================] - 6s 7ms/step - loss: 0.5067 - accuracy: 0.7399 - auc: 0.8264 - val_loss: 0.5216 - val_accuracy: 0.7316 - val_auc: 0.8208\n",
      "Epoch 14/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.5016 - accuracy: 0.7454 - auc: 0.8306 - val_loss: 0.5136 - val_accuracy: 0.7369 - val_auc: 0.8229\n",
      "Epoch 15/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.5001 - accuracy: 0.7452 - auc: 0.8325 - val_loss: 0.5131 - val_accuracy: 0.7390 - val_auc: 0.8250\n",
      "Epoch 16/100\n",
      "763/763 [==============================] - 6s 7ms/step - loss: 0.4950 - accuracy: 0.7496 - auc: 0.8353 - val_loss: 0.5125 - val_accuracy: 0.7439 - val_auc: 0.8267\n",
      "Epoch 17/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.4919 - accuracy: 0.7514 - auc: 0.8381 - val_loss: 0.5109 - val_accuracy: 0.7351 - val_auc: 0.8265\n",
      "Epoch 18/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.4882 - accuracy: 0.7539 - auc: 0.8402 - val_loss: 0.5056 - val_accuracy: 0.7506 - val_auc: 0.8322\n",
      "Epoch 19/100\n",
      "763/763 [==============================] - 6s 7ms/step - loss: 0.4838 - accuracy: 0.7599 - auc: 0.8439 - val_loss: 0.4989 - val_accuracy: 0.7490 - val_auc: 0.8347\n",
      "Epoch 20/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.4791 - accuracy: 0.7600 - auc: 0.8470 - val_loss: 0.5155 - val_accuracy: 0.7367 - val_auc: 0.8285\n",
      "Epoch 21/100\n",
      "763/763 [==============================] - 6s 8ms/step - loss: 0.4775 - accuracy: 0.7610 - auc: 0.8488 - val_loss: 0.4969 - val_accuracy: 0.7499 - val_auc: 0.8355\n",
      "Epoch 22/100\n",
      "763/763 [==============================] - 6s 7ms/step - loss: 0.4724 - accuracy: 0.7632 - auc: 0.8514 - val_loss: 0.4988 - val_accuracy: 0.7485 - val_auc: 0.8381\n",
      "Epoch 23/100\n",
      "763/763 [==============================] - 6s 8ms/step - loss: 0.4685 - accuracy: 0.7655 - auc: 0.8546 - val_loss: 0.5158 - val_accuracy: 0.7441 - val_auc: 0.8334\n",
      "Epoch 24/100\n",
      "763/763 [==============================] - 6s 7ms/step - loss: 0.4677 - accuracy: 0.7688 - auc: 0.8552 - val_loss: 0.5036 - val_accuracy: 0.7425 - val_auc: 0.8430\n",
      "Epoch 25/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.4621 - accuracy: 0.7701 - auc: 0.8586 - val_loss: 0.4928 - val_accuracy: 0.7555 - val_auc: 0.8391\n",
      "Epoch 26/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.4586 - accuracy: 0.7703 - auc: 0.8608 - val_loss: 0.4908 - val_accuracy: 0.7592 - val_auc: 0.8438\n",
      "Epoch 27/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.4561 - accuracy: 0.7719 - auc: 0.8624 - val_loss: 0.4973 - val_accuracy: 0.7490 - val_auc: 0.8399\n",
      "Epoch 28/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.4537 - accuracy: 0.7767 - auc: 0.8649 - val_loss: 0.4945 - val_accuracy: 0.7550 - val_auc: 0.8438\n",
      "Epoch 29/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.4494 - accuracy: 0.7767 - auc: 0.8674 - val_loss: 0.4924 - val_accuracy: 0.7550 - val_auc: 0.8479\n",
      "Epoch 30/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.4447 - accuracy: 0.7803 - auc: 0.8705 - val_loss: 0.5007 - val_accuracy: 0.7506 - val_auc: 0.8454\n",
      "Epoch 31/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.4411 - accuracy: 0.7854 - auc: 0.8729 - val_loss: 0.4863 - val_accuracy: 0.7597 - val_auc: 0.8472\n",
      "Epoch 32/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.4394 - accuracy: 0.7829 - auc: 0.8740 - val_loss: 0.4887 - val_accuracy: 0.7585 - val_auc: 0.8461\n",
      "Epoch 33/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.4341 - accuracy: 0.7866 - auc: 0.8780 - val_loss: 0.4832 - val_accuracy: 0.7597 - val_auc: 0.8516\n",
      "Epoch 34/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.4296 - accuracy: 0.7891 - auc: 0.8801 - val_loss: 0.5028 - val_accuracy: 0.7550 - val_auc: 0.8476\n",
      "Epoch 35/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.4264 - accuracy: 0.7923 - auc: 0.8822 - val_loss: 0.4905 - val_accuracy: 0.7667 - val_auc: 0.8524\n",
      "Epoch 36/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.4263 - accuracy: 0.7948 - auc: 0.8837 - val_loss: 0.4924 - val_accuracy: 0.7620 - val_auc: 0.8530\n",
      "Epoch 37/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.4191 - accuracy: 0.7964 - auc: 0.8860 - val_loss: 0.4934 - val_accuracy: 0.7597 - val_auc: 0.8468\n",
      "Epoch 38/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.4145 - accuracy: 0.8023 - auc: 0.8895 - val_loss: 0.4749 - val_accuracy: 0.7776 - val_auc: 0.8614\n",
      "Epoch 39/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.4110 - accuracy: 0.7986 - auc: 0.8905 - val_loss: 0.4775 - val_accuracy: 0.7748 - val_auc: 0.8562\n",
      "Epoch 40/100\n",
      "763/763 [==============================] - 6s 7ms/step - loss: 0.4117 - accuracy: 0.8033 - auc: 0.8914 - val_loss: 0.4862 - val_accuracy: 0.7655 - val_auc: 0.8564\n",
      "Epoch 41/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.4106 - accuracy: 0.8041 - auc: 0.8918 - val_loss: 0.4732 - val_accuracy: 0.7725 - val_auc: 0.8599\n",
      "Epoch 42/100\n",
      "763/763 [==============================] - 6s 7ms/step - loss: 0.4035 - accuracy: 0.8072 - auc: 0.8964 - val_loss: 0.4750 - val_accuracy: 0.7720 - val_auc: 0.8601\n",
      "Epoch 43/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.3979 - accuracy: 0.8104 - auc: 0.8988 - val_loss: 0.4819 - val_accuracy: 0.7776 - val_auc: 0.8627\n",
      "Epoch 44/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.3984 - accuracy: 0.8131 - auc: 0.8990 - val_loss: 0.4847 - val_accuracy: 0.7722 - val_auc: 0.8603\n",
      "Epoch 45/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.3906 - accuracy: 0.8150 - auc: 0.9027 - val_loss: 0.4799 - val_accuracy: 0.7674 - val_auc: 0.8587\n",
      "Epoch 46/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.3902 - accuracy: 0.8150 - auc: 0.9032 - val_loss: 0.4768 - val_accuracy: 0.7773 - val_auc: 0.8633\n",
      "Epoch 47/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.3859 - accuracy: 0.8183 - auc: 0.9049 - val_loss: 0.4703 - val_accuracy: 0.7841 - val_auc: 0.8654\n",
      "Epoch 48/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.3811 - accuracy: 0.8234 - auc: 0.9083 - val_loss: 0.4706 - val_accuracy: 0.7811 - val_auc: 0.8679\n",
      "Epoch 49/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.3805 - accuracy: 0.8211 - auc: 0.9084 - val_loss: 0.4691 - val_accuracy: 0.7824 - val_auc: 0.8691\n",
      "Epoch 50/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.3701 - accuracy: 0.8278 - auc: 0.9134 - val_loss: 0.4612 - val_accuracy: 0.7880 - val_auc: 0.8707\n",
      "Epoch 51/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.3693 - accuracy: 0.8279 - auc: 0.9138 - val_loss: 0.4781 - val_accuracy: 0.7876 - val_auc: 0.8688\n",
      "Epoch 52/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.3655 - accuracy: 0.8305 - auc: 0.9158 - val_loss: 0.4742 - val_accuracy: 0.7850 - val_auc: 0.8681\n",
      "Epoch 53/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.3651 - accuracy: 0.8332 - auc: 0.9160 - val_loss: 0.4596 - val_accuracy: 0.7929 - val_auc: 0.8767\n",
      "Epoch 54/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.3576 - accuracy: 0.8338 - auc: 0.9197 - val_loss: 0.4737 - val_accuracy: 0.7924 - val_auc: 0.8749\n",
      "Epoch 55/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.3590 - accuracy: 0.8346 - auc: 0.9189 - val_loss: 0.4749 - val_accuracy: 0.7883 - val_auc: 0.8748\n",
      "Epoch 56/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.3559 - accuracy: 0.8379 - auc: 0.9205 - val_loss: 0.4766 - val_accuracy: 0.7917 - val_auc: 0.8725\n",
      "Epoch 57/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.3516 - accuracy: 0.8414 - auc: 0.9230 - val_loss: 0.4634 - val_accuracy: 0.8003 - val_auc: 0.8760\n",
      "Epoch 58/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.3508 - accuracy: 0.8400 - auc: 0.9227 - val_loss: 0.4680 - val_accuracy: 0.7924 - val_auc: 0.8752\n",
      "Epoch 59/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.3494 - accuracy: 0.8438 - auc: 0.9246 - val_loss: 0.4803 - val_accuracy: 0.7968 - val_auc: 0.8732\n",
      "Epoch 60/100\n",
      "763/763 [==============================] - 6s 7ms/step - loss: 0.3416 - accuracy: 0.8459 - auc: 0.9274 - val_loss: 0.4589 - val_accuracy: 0.7957 - val_auc: 0.8782\n",
      "Epoch 61/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.3414 - accuracy: 0.8427 - auc: 0.9269 - val_loss: 0.4612 - val_accuracy: 0.7992 - val_auc: 0.8798\n",
      "Epoch 62/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.3354 - accuracy: 0.8487 - auc: 0.9303 - val_loss: 0.4690 - val_accuracy: 0.7992 - val_auc: 0.8797\n",
      "Epoch 63/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.3313 - accuracy: 0.8502 - auc: 0.9314 - val_loss: 0.4541 - val_accuracy: 0.8006 - val_auc: 0.8822\n",
      "Epoch 64/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.3309 - accuracy: 0.8496 - auc: 0.9314 - val_loss: 0.4499 - val_accuracy: 0.7996 - val_auc: 0.8840\n",
      "Epoch 65/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.3335 - accuracy: 0.8505 - auc: 0.9327 - val_loss: 0.4577 - val_accuracy: 0.8087 - val_auc: 0.8835\n",
      "Epoch 66/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.3260 - accuracy: 0.8536 - auc: 0.9341 - val_loss: 0.4842 - val_accuracy: 0.7978 - val_auc: 0.8803\n",
      "Epoch 67/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.3272 - accuracy: 0.8531 - auc: 0.9334 - val_loss: 0.4561 - val_accuracy: 0.7992 - val_auc: 0.8865\n",
      "Epoch 68/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.3161 - accuracy: 0.8566 - auc: 0.9382 - val_loss: 0.4758 - val_accuracy: 0.7894 - val_auc: 0.8781\n",
      "Epoch 69/100\n",
      "763/763 [==============================] - 6s 7ms/step - loss: 0.3134 - accuracy: 0.8585 - auc: 0.9391 - val_loss: 0.4605 - val_accuracy: 0.8036 - val_auc: 0.8846\n",
      "Epoch 70/100\n",
      "763/763 [==============================] - 7s 10ms/step - loss: 0.3146 - accuracy: 0.8600 - auc: 0.9384 - val_loss: 0.4661 - val_accuracy: 0.8040 - val_auc: 0.8870\n",
      "Epoch 71/100\n",
      "763/763 [==============================] - 7s 9ms/step - loss: 0.3117 - accuracy: 0.8607 - auc: 0.9399 - val_loss: 0.4587 - val_accuracy: 0.8024 - val_auc: 0.8862\n",
      "Epoch 72/100\n",
      "763/763 [==============================] - 6s 8ms/step - loss: 0.3097 - accuracy: 0.8606 - auc: 0.9408 - val_loss: 0.4586 - val_accuracy: 0.8112 - val_auc: 0.8892\n",
      "Epoch 73/100\n",
      "763/763 [==============================] - 7s 10ms/step - loss: 0.3111 - accuracy: 0.8613 - auc: 0.9403 - val_loss: 0.4570 - val_accuracy: 0.8085 - val_auc: 0.8889\n",
      "Epoch 74/100\n",
      "763/763 [==============================] - 7s 9ms/step - loss: 0.3039 - accuracy: 0.8664 - auc: 0.9431 - val_loss: 0.4660 - val_accuracy: 0.8068 - val_auc: 0.8873\n",
      "Epoch 75/100\n",
      "763/763 [==============================] - 7s 9ms/step - loss: 0.3044 - accuracy: 0.8654 - auc: 0.9434 - val_loss: 0.4800 - val_accuracy: 0.8075 - val_auc: 0.8854\n",
      "Epoch 76/100\n",
      "763/763 [==============================] - 7s 9ms/step - loss: 0.2969 - accuracy: 0.8691 - auc: 0.9457 - val_loss: 0.4955 - val_accuracy: 0.8008 - val_auc: 0.8879\n",
      "Epoch 77/100\n",
      "763/763 [==============================] - 6s 8ms/step - loss: 0.2919 - accuracy: 0.8701 - auc: 0.9471 - val_loss: 0.4600 - val_accuracy: 0.8182 - val_auc: 0.8938\n",
      "Epoch 78/100\n",
      "763/763 [==============================] - 6s 8ms/step - loss: 0.2934 - accuracy: 0.8707 - auc: 0.9472 - val_loss: 0.4677 - val_accuracy: 0.8138 - val_auc: 0.8917\n",
      "Epoch 79/100\n",
      "763/763 [==============================] - 6s 8ms/step - loss: 0.2933 - accuracy: 0.8703 - auc: 0.9471 - val_loss: 0.4804 - val_accuracy: 0.8152 - val_auc: 0.8893\n",
      "Epoch 80/100\n",
      "763/763 [==============================] - 6s 8ms/step - loss: 0.2931 - accuracy: 0.8711 - auc: 0.9485 - val_loss: 0.4764 - val_accuracy: 0.8163 - val_auc: 0.8911\n",
      "Epoch 81/100\n",
      "763/763 [==============================] - 6s 8ms/step - loss: 0.2875 - accuracy: 0.8744 - auc: 0.9493 - val_loss: 0.4667 - val_accuracy: 0.8152 - val_auc: 0.8923\n",
      "Epoch 82/100\n",
      "763/763 [==============================] - 6s 8ms/step - loss: 0.2845 - accuracy: 0.8738 - auc: 0.9506 - val_loss: 0.4737 - val_accuracy: 0.8124 - val_auc: 0.8924\n",
      "Epoch 83/100\n",
      "763/763 [==============================] - 6s 7ms/step - loss: 0.2813 - accuracy: 0.8743 - auc: 0.9514 - val_loss: 0.4848 - val_accuracy: 0.8096 - val_auc: 0.8900\n",
      "Epoch 84/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.2810 - accuracy: 0.8777 - auc: 0.9516 - val_loss: 0.4736 - val_accuracy: 0.8117 - val_auc: 0.8924\n",
      "Epoch 85/100\n",
      "763/763 [==============================] - 6s 8ms/step - loss: 0.2791 - accuracy: 0.8775 - auc: 0.9520 - val_loss: 0.4752 - val_accuracy: 0.8161 - val_auc: 0.8938\n",
      "Epoch 86/100\n",
      "763/763 [==============================] - 6s 7ms/step - loss: 0.2742 - accuracy: 0.8810 - auc: 0.9542 - val_loss: 0.4622 - val_accuracy: 0.8170 - val_auc: 0.8953\n",
      "Epoch 87/100\n",
      "763/763 [==============================] - 6s 7ms/step - loss: 0.2767 - accuracy: 0.8792 - auc: 0.9530 - val_loss: 0.4849 - val_accuracy: 0.8168 - val_auc: 0.8945\n",
      "135/135 [==============================] - 0s 2ms/step\n",
      "ROC-AUC: 0.8940019894829287\n",
      "Accuracy: 0.8182029254701648\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, LSTM, Dropout, Input, concatenate\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "dropout=0.1\n",
    "lstm_units = 256\n",
    "lstm_units2 = 128\n",
    "dense_units = 64\n",
    "\n",
    "\n",
    "# First branch for the LSTM\n",
    "lstm_input = Input(shape=(1, 100))\n",
    "lstm_output = LSTM(units=lstm_units, return_sequences=True, activation='relu')(lstm_input)\n",
    "lstm_output = Dropout(dropout)(lstm_output)\n",
    "lstm_output = LSTM(units=lstm_units2, activation='relu')(lstm_output)\n",
    "lstm_output = Dropout(dropout)(lstm_output)\n",
    "\n",
    "# Second branch for the dense layers\n",
    "dense_input = Input(shape=(5,))\n",
    "dense_output = Dense(units=dense_units, activation='relu')(dense_input)\n",
    "dense_output = Dropout(dropout)(dense_output)\n",
    "\n",
    "# Concatenate the outputs from both branches\n",
    "combined = concatenate([lstm_output, dense_output])\n",
    "\n",
    "combined = Dense(units = dense_units, activation='relu')(combined)\n",
    "\n",
    "# Final output layer\n",
    "output = Dense(units=1, activation='sigmoid')(combined)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=[lstm_input, dense_input], outputs=output)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', 'AUC'])\n",
    "\n",
    "# Define the early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model with both LSTM and dense input\n",
    "model.fit([X_train_vec, X_train], y_train, epochs=100, batch_size=32,\n",
    "          validation_data=([X_test_vec, X_test], y_test),\n",
    "          callbacks=[early_stopping])\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict([X_test_vec, X_test])\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "y_pred_class = (y_pred > .5).astype(int)\n",
    "accuracy = accuracy_score(y_test,y_pred_class)\n",
    "print('ROC-AUC:', roc_auc)\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "matrix = confusion_matrix(y_test, y_pred_class)\n",
    "\n",
    "sns.heatmap(matrix/np.sum(matrix), annot=True, fmt='.2%', cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59dc53ff-9c21-466a-8e9f-f10b3833b0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model containing character length, number of capital words, upvotes and # of comments\n",
    "#Model 2 adds POS tagging and standard scaling of variables\n",
    "#Only left in proper nouns as others decreased performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77a3b55f-1112-4739-b2cf-337ce0205e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "#create extra variables for later\n",
    "df_other_var = create_other_var(df)\n",
    "\n",
    "#Create simple dataframe with only text and predictor\n",
    "df = df[['Title','Political Lean']] \n",
    "\n",
    "#dummy code predictor\n",
    "df['Political Lean'] = df['Political Lean'].replace('Liberal',1)\n",
    "df['Political Lean'] = df['Political Lean'].replace('Conservative',0)\n",
    "\n",
    "df = df.rename({'Political Lean':'y'},axis=1) #replace column name for simplicity\n",
    "\n",
    "df = pd.concat([df,df_other_var],axis=1)\n",
    "\n",
    "df = df[df['Length']>=15]\n",
    "\n",
    "#Split into X & y\n",
    "X = df.drop(['y'],axis=1)\n",
    "y = df['y']\n",
    "\n",
    "#oversample minority class\n",
    "oversample = RandomOverSampler(sampling_strategy='minority', random_state=13)\n",
    "X, y = oversample.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eed9495c-923f-474f-9f74-dd19b9ac4074",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'merge'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m loss_df \u001b[38;5;241m=\u001b[39m \u001b[43mX_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m(X[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTitle\u001b[39m\u001b[38;5;124m'\u001b[39m]],left_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,right_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m loss_df \u001b[38;5;241m=\u001b[39m loss_df\u001b[38;5;241m.\u001b[39mmerge(y,left_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,right_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m predictions \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(y_pred, columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprob\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'merge'"
     ]
    }
   ],
   "source": [
    "loss_df = X_test.merge(X[['Title']],left_index=True,right_index=True,how='left')\n",
    "loss_df = loss_df.merge(y,left_index=True,right_index=True,how='left')\n",
    "predictions = pd.DataFrame(y_pred, columns = ['prob'])\n",
    "loss_df = pd.concat([loss_df,predictions.set_index(loss_df.index)],axis=1)\n",
    "loss_df['prob'] = abs(loss_df['prob']-.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83928af4-ce6f-427f-89a2-874bc4d50d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_df.sort_values(by='prob').head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ea316a-dd0e-403b-941b-a187813ce181",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LHL_env",
   "language": "python",
   "name": "lhl_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
