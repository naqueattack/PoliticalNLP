{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67233b73-f1a2-4cab-a395-0acf30fb4ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Andrew\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Andrew\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "df = pd.read_csv(\"../data/fulldata.csv\")\n",
    "df2 = pd.read_csv(\"../data/6_14_pull.csv\")\n",
    "\n",
    "df = pd.concat([df,df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a16c2532-c2f2-48f7-84f6-7f9e0049ea0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Cleaning import lowercase, unpunctuate, tokenize, lemmatize, count_capitalized_words, create_other_var, cleaning_and_prep, stack_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb47f54a-ec57-4308-a10d-62853364b7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andrew\\Documents\\LHL\\PoliticalNLP\\python\\Cleaning.py:127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Political Lean'] = df['Political Lean'].replace('Liberal',1)\n",
      "C:\\Users\\Andrew\\Documents\\LHL\\PoliticalNLP\\python\\Cleaning.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Political Lean'] = df['Political Lean'].replace('Conservative',0)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = cleaning_and_prep(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c07ff43-bee3-4c11-9e29-29c25764a85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vec, X_test_vec, X_train, X_test = stack_vectors(X_train,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83645586-d576-4de0-ae1e-d3897c0b206b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "763/763 [==============================] - 6s 5ms/step - loss: 0.6168 - accuracy: 0.6598 - auc: 0.7283 - val_loss: 0.5662 - val_accuracy: 0.7077 - val_auc: 0.7889\n",
      "Epoch 2/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5838 - accuracy: 0.6837 - auc: 0.7599 - val_loss: 0.5627 - val_accuracy: 0.6928 - val_auc: 0.7948\n",
      "Epoch 3/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5740 - accuracy: 0.6919 - auc: 0.7673 - val_loss: 0.5505 - val_accuracy: 0.7165 - val_auc: 0.7947\n",
      "Epoch 4/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5706 - accuracy: 0.6973 - auc: 0.7718 - val_loss: 0.5356 - val_accuracy: 0.7198 - val_auc: 0.8025\n",
      "Epoch 5/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5666 - accuracy: 0.7001 - auc: 0.7767 - val_loss: 0.5486 - val_accuracy: 0.7126 - val_auc: 0.7966\n",
      "Epoch 6/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5610 - accuracy: 0.6988 - auc: 0.7797 - val_loss: 0.5330 - val_accuracy: 0.7263 - val_auc: 0.8132\n",
      "Epoch 7/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5604 - accuracy: 0.7058 - auc: 0.7833 - val_loss: 0.5299 - val_accuracy: 0.7281 - val_auc: 0.8100\n",
      "Epoch 8/100\n",
      "763/763 [==============================] - 4s 6ms/step - loss: 0.5544 - accuracy: 0.7078 - auc: 0.7872 - val_loss: 0.5386 - val_accuracy: 0.7251 - val_auc: 0.8082\n",
      "Epoch 9/100\n",
      "763/763 [==============================] - 5s 6ms/step - loss: 0.5561 - accuracy: 0.7070 - auc: 0.7853 - val_loss: 0.5324 - val_accuracy: 0.7267 - val_auc: 0.8087\n",
      "Epoch 10/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5514 - accuracy: 0.7077 - auc: 0.7896 - val_loss: 0.5440 - val_accuracy: 0.7010 - val_auc: 0.7902\n",
      "Epoch 11/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.5553 - accuracy: 0.7091 - auc: 0.7874 - val_loss: 0.5316 - val_accuracy: 0.7209 - val_auc: 0.8112\n",
      "Epoch 12/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.5499 - accuracy: 0.7114 - auc: 0.7905 - val_loss: 0.5356 - val_accuracy: 0.7112 - val_auc: 0.8105\n",
      "Epoch 13/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5516 - accuracy: 0.7088 - auc: 0.7890 - val_loss: 0.5352 - val_accuracy: 0.7279 - val_auc: 0.8044\n",
      "Epoch 14/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5498 - accuracy: 0.7121 - auc: 0.7913 - val_loss: 0.5286 - val_accuracy: 0.7318 - val_auc: 0.8183\n",
      "Epoch 15/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5524 - accuracy: 0.7089 - auc: 0.7891 - val_loss: 0.5282 - val_accuracy: 0.7335 - val_auc: 0.8160\n",
      "Epoch 16/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5496 - accuracy: 0.7119 - auc: 0.7930 - val_loss: 0.5248 - val_accuracy: 0.7300 - val_auc: 0.8141\n",
      "Epoch 17/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5440 - accuracy: 0.7113 - auc: 0.7949 - val_loss: 0.5227 - val_accuracy: 0.7295 - val_auc: 0.8185\n",
      "Epoch 18/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5463 - accuracy: 0.7135 - auc: 0.7943 - val_loss: 0.5211 - val_accuracy: 0.7386 - val_auc: 0.8178\n",
      "Epoch 19/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5457 - accuracy: 0.7116 - auc: 0.7953 - val_loss: 0.5238 - val_accuracy: 0.7339 - val_auc: 0.8173\n",
      "Epoch 20/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5416 - accuracy: 0.7157 - auc: 0.7979 - val_loss: 0.5223 - val_accuracy: 0.7265 - val_auc: 0.8181\n",
      "Epoch 21/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5434 - accuracy: 0.7160 - auc: 0.7973 - val_loss: 0.5301 - val_accuracy: 0.7249 - val_auc: 0.8131\n",
      "Epoch 22/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5425 - accuracy: 0.7172 - auc: 0.7975 - val_loss: 0.5159 - val_accuracy: 0.7353 - val_auc: 0.8202\n",
      "Epoch 23/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5378 - accuracy: 0.7182 - auc: 0.8006 - val_loss: 0.5147 - val_accuracy: 0.7316 - val_auc: 0.8206\n",
      "Epoch 24/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5403 - accuracy: 0.7156 - auc: 0.7988 - val_loss: 0.5172 - val_accuracy: 0.7295 - val_auc: 0.8196\n",
      "Epoch 25/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5432 - accuracy: 0.7149 - auc: 0.7971 - val_loss: 0.5282 - val_accuracy: 0.7346 - val_auc: 0.8207\n",
      "Epoch 26/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5405 - accuracy: 0.7172 - auc: 0.8001 - val_loss: 0.5328 - val_accuracy: 0.7207 - val_auc: 0.8227\n",
      "Epoch 27/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5420 - accuracy: 0.7181 - auc: 0.7985 - val_loss: 0.5149 - val_accuracy: 0.7472 - val_auc: 0.8223\n",
      "Epoch 28/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5426 - accuracy: 0.7168 - auc: 0.7987 - val_loss: 0.5254 - val_accuracy: 0.7351 - val_auc: 0.8151\n",
      "Epoch 29/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5422 - accuracy: 0.7168 - auc: 0.7974 - val_loss: 0.5213 - val_accuracy: 0.7379 - val_auc: 0.8221\n",
      "Epoch 30/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5387 - accuracy: 0.7187 - auc: 0.8013 - val_loss: 0.5122 - val_accuracy: 0.7330 - val_auc: 0.8256\n",
      "Epoch 31/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5370 - accuracy: 0.7194 - auc: 0.8025 - val_loss: 0.5170 - val_accuracy: 0.7409 - val_auc: 0.8212\n",
      "Epoch 32/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5352 - accuracy: 0.7182 - auc: 0.8028 - val_loss: 0.5186 - val_accuracy: 0.7400 - val_auc: 0.8229\n",
      "Epoch 33/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5409 - accuracy: 0.7228 - auc: 0.8031 - val_loss: 0.5140 - val_accuracy: 0.7414 - val_auc: 0.8231\n",
      "Epoch 34/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5333 - accuracy: 0.7227 - auc: 0.8046 - val_loss: 0.5095 - val_accuracy: 0.7474 - val_auc: 0.8278\n",
      "Epoch 35/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5369 - accuracy: 0.7196 - auc: 0.8035 - val_loss: 0.5136 - val_accuracy: 0.7451 - val_auc: 0.8246\n",
      "Epoch 36/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5385 - accuracy: 0.7229 - auc: 0.8031 - val_loss: 0.5165 - val_accuracy: 0.7418 - val_auc: 0.8218\n",
      "Epoch 37/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5339 - accuracy: 0.7218 - auc: 0.8045 - val_loss: 0.5218 - val_accuracy: 0.7242 - val_auc: 0.8201\n",
      "Epoch 38/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5323 - accuracy: 0.7212 - auc: 0.8058 - val_loss: 0.5115 - val_accuracy: 0.7418 - val_auc: 0.8247\n",
      "Epoch 39/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5317 - accuracy: 0.7246 - auc: 0.8073 - val_loss: 0.5279 - val_accuracy: 0.7330 - val_auc: 0.8167\n",
      "Epoch 40/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5354 - accuracy: 0.7214 - auc: 0.8040 - val_loss: 0.5233 - val_accuracy: 0.7267 - val_auc: 0.8185\n",
      "Epoch 41/100\n",
      "763/763 [==============================] - 5s 6ms/step - loss: 0.5340 - accuracy: 0.7223 - auc: 0.8040 - val_loss: 0.5137 - val_accuracy: 0.7360 - val_auc: 0.8246\n",
      "Epoch 42/100\n",
      "763/763 [==============================] - 4s 6ms/step - loss: 0.5318 - accuracy: 0.7253 - auc: 0.8063 - val_loss: 0.5129 - val_accuracy: 0.7330 - val_auc: 0.8262\n",
      "Epoch 43/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5329 - accuracy: 0.7255 - auc: 0.8065 - val_loss: 0.5066 - val_accuracy: 0.7427 - val_auc: 0.8280\n",
      "Epoch 44/100\n",
      "763/763 [==============================] - 4s 6ms/step - loss: 0.5300 - accuracy: 0.7245 - auc: 0.8080 - val_loss: 0.5036 - val_accuracy: 0.7495 - val_auc: 0.8340\n",
      "Epoch 45/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5299 - accuracy: 0.7235 - auc: 0.8073 - val_loss: 0.5140 - val_accuracy: 0.7335 - val_auc: 0.8249\n",
      "Epoch 46/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5305 - accuracy: 0.7240 - auc: 0.8089 - val_loss: 0.5064 - val_accuracy: 0.7416 - val_auc: 0.8296\n",
      "Epoch 47/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5303 - accuracy: 0.7264 - auc: 0.8080 - val_loss: 0.4992 - val_accuracy: 0.7492 - val_auc: 0.8341\n",
      "Epoch 48/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5314 - accuracy: 0.7248 - auc: 0.8083 - val_loss: 0.5085 - val_accuracy: 0.7395 - val_auc: 0.8281\n",
      "Epoch 49/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5330 - accuracy: 0.7271 - auc: 0.8075 - val_loss: 0.5222 - val_accuracy: 0.7360 - val_auc: 0.8228\n",
      "Epoch 50/100\n",
      "763/763 [==============================] - 4s 5ms/step - loss: 0.5307 - accuracy: 0.7220 - auc: 0.8071 - val_loss: 0.5133 - val_accuracy: 0.7441 - val_auc: 0.8275\n",
      "Epoch 51/100\n",
      "501/763 [==================>...........] - ETA: 1s - loss: 0.5322 - accuracy: 0.7236 - auc: 0.8057"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, LSTM, Dropout, Input, concatenate\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "# First branch for the LSTM\n",
    "lstm_input = Input(shape=(1, 100))\n",
    "lstm_output = LSTM(units=256, return_sequences=True, activation='relu')(lstm_input)\n",
    "lstm_output = Dropout(0.2)(lstm_output)\n",
    "lstm_output = LSTM(units=128, activation='relu')(lstm_output)\n",
    "lstm_output = Dropout(0.2)(lstm_output)\n",
    "\n",
    "# Second branch for the dense layers\n",
    "dense_input = Input(shape=(5,))\n",
    "dense_output = Dense(units=64, activation='relu')(dense_input)\n",
    "dense_output = Dropout(0.2)(dense_output)\n",
    "\n",
    "# Concatenate the outputs from both branches\n",
    "combined = concatenate([lstm_output, dense_output])\n",
    "\n",
    "combined = Dense(units = 64, activation='relu')(combined)\n",
    "\n",
    "# Final output layer\n",
    "output = Dense(units=1, activation='sigmoid')(combined)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=[lstm_input, dense_input], outputs=output)\n",
    "model.compile(optimizer=Adam(learning_rate=0.01), loss='binary_crossentropy', metrics=['accuracy', 'AUC'])\n",
    "\n",
    "# Define the early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model with both LSTM and dense input\n",
    "model.fit([X_train_vec, X_train], y_train, epochs=100, batch_size=32,\n",
    "          validation_data=([X_test_vec, X_test], y_test),\n",
    "          callbacks=[early_stopping])\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict([X_test_vec, X_test])\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "y_pred_class = (y_pred > .5).astype(int)\n",
    "accuracy = accuracy_score(y_test,y_pred_class)\n",
    "print('ROC-AUC:', roc_auc)\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "matrix = confusion_matrix(y_test, y_pred_class)\n",
    "\n",
    "sns.heatmap(matrix/np.sum(matrix), annot=True, fmt='.2%', cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dc53ff-9c21-466a-8e9f-f10b3833b0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model containing character length, number of capital words, upvotes and # of comments\n",
    "#Model 2 adds POS tagging and standard scaling of variables\n",
    "#Only left in proper nouns as others decreased performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a3b55f-1112-4739-b2cf-337ce0205e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "#create extra variables for later\n",
    "df_other_var = create_other_var(df)\n",
    "\n",
    "#Create simple dataframe with only text and predictor\n",
    "df = df[['Title','Political Lean']] \n",
    "\n",
    "#dummy code predictor\n",
    "df['Political Lean'] = df['Political Lean'].replace('Liberal',1)\n",
    "df['Political Lean'] = df['Political Lean'].replace('Conservative',0)\n",
    "\n",
    "df = df.rename({'Political Lean':'y'},axis=1) #replace column name for simplicity\n",
    "\n",
    "df = pd.concat([df,df_other_var],axis=1)\n",
    "\n",
    "df = df[df['Length']>=15]\n",
    "\n",
    "#Split into X & y\n",
    "X = df.drop(['y'],axis=1)\n",
    "y = df['y']\n",
    "\n",
    "#oversample minority class\n",
    "oversample = RandomOverSampler(sampling_strategy='minority', random_state=13)\n",
    "X, y = oversample.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed9495c-923f-474f-9f74-dd19b9ac4074",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_df = X_test.merge(X[['Title']],left_index=True,right_index=True,how='left')\n",
    "loss_df = loss_df.merge(y,left_index=True,right_index=True,how='left')\n",
    "predictions = pd.DataFrame(y_pred, columns = ['prob'])\n",
    "loss_df = pd.concat([loss_df,predictions.set_index(loss_df.index)],axis=1)\n",
    "loss_df['prob'] = abs(loss_df['prob']-.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83928af4-ce6f-427f-89a2-874bc4d50d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_df.sort_values(by='prob').head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ea316a-dd0e-403b-941b-a187813ce181",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LHL_env",
   "language": "python",
   "name": "lhl_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
