{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67233b73-f1a2-4cab-a395-0acf30fb4ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Andrew\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Andrew\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "df = pd.read_csv(\"../data/fulldata.csv\")\n",
    "df2 = pd.read_csv(\"../data/6_14_pull.csv\")\n",
    "\n",
    "df = pd.concat([df,df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a16c2532-c2f2-48f7-84f6-7f9e0049ea0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Cleaning import lowercase, unpunctuate, tokenize, lemmatize, count_capitalized_words, create_other_var, cleaning_and_prep, stack_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb47f54a-ec57-4308-a10d-62853364b7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andrew\\Documents\\LHL\\PoliticalNLP\\python\\Cleaning.py:127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Political Lean'] = df['Political Lean'].replace('Liberal',1)\n",
      "C:\\Users\\Andrew\\Documents\\LHL\\PoliticalNLP\\python\\Cleaning.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Political Lean'] = df['Political Lean'].replace('Conservative',0)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = cleaning_and_prep(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c07ff43-bee3-4c11-9e29-29c25764a85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vec, X_test_vec, X_train, X_test = stack_vectors(X_train,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83645586-d576-4de0-ae1e-d3897c0b206b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "763/763 [==============================] - 11s 11ms/step - loss: 0.6137 - accuracy: 0.6566 - auc: 0.7245 - val_loss: 0.5941 - val_accuracy: 0.6703 - val_auc: 0.7506\n",
      "Epoch 2/100\n",
      "763/763 [==============================] - 6s 8ms/step - loss: 0.5757 - accuracy: 0.6916 - auc: 0.7669 - val_loss: 0.5727 - val_accuracy: 0.6821 - val_auc: 0.7726\n",
      "Epoch 3/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.5632 - accuracy: 0.6972 - auc: 0.7782 - val_loss: 0.5650 - val_accuracy: 0.6921 - val_auc: 0.7755\n",
      "Epoch 4/100\n",
      "763/763 [==============================] - 6s 7ms/step - loss: 0.5549 - accuracy: 0.7065 - auc: 0.7861 - val_loss: 0.5555 - val_accuracy: 0.7054 - val_auc: 0.7830\n",
      "Epoch 5/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.5467 - accuracy: 0.7123 - auc: 0.7930 - val_loss: 0.5576 - val_accuracy: 0.6945 - val_auc: 0.7863\n",
      "Epoch 6/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.5419 - accuracy: 0.7154 - auc: 0.7967 - val_loss: 0.5506 - val_accuracy: 0.7044 - val_auc: 0.7914\n",
      "Epoch 7/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.5364 - accuracy: 0.7198 - auc: 0.8015 - val_loss: 0.5445 - val_accuracy: 0.7112 - val_auc: 0.7928\n",
      "Epoch 8/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.5340 - accuracy: 0.7226 - auc: 0.8057 - val_loss: 0.5447 - val_accuracy: 0.7049 - val_auc: 0.7942\n",
      "Epoch 9/100\n",
      "763/763 [==============================] - 6s 7ms/step - loss: 0.5298 - accuracy: 0.7233 - auc: 0.8079 - val_loss: 0.5396 - val_accuracy: 0.7179 - val_auc: 0.8006\n",
      "Epoch 10/100\n",
      "763/763 [==============================] - 6s 7ms/step - loss: 0.5264 - accuracy: 0.7289 - auc: 0.8109 - val_loss: 0.5366 - val_accuracy: 0.7147 - val_auc: 0.8011\n",
      "Epoch 11/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.5223 - accuracy: 0.7307 - auc: 0.8155 - val_loss: 0.5341 - val_accuracy: 0.7200 - val_auc: 0.8049\n",
      "Epoch 12/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.5174 - accuracy: 0.7341 - auc: 0.8179 - val_loss: 0.5378 - val_accuracy: 0.7198 - val_auc: 0.8017\n",
      "Epoch 13/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.5147 - accuracy: 0.7361 - auc: 0.8201 - val_loss: 0.5343 - val_accuracy: 0.7186 - val_auc: 0.8054\n",
      "Epoch 14/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.5106 - accuracy: 0.7401 - auc: 0.8233 - val_loss: 0.5268 - val_accuracy: 0.7230 - val_auc: 0.8105\n",
      "Epoch 15/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.5075 - accuracy: 0.7385 - auc: 0.8261 - val_loss: 0.5301 - val_accuracy: 0.7244 - val_auc: 0.8098\n",
      "Epoch 16/100\n",
      "763/763 [==============================] - 6s 7ms/step - loss: 0.5050 - accuracy: 0.7406 - auc: 0.8271 - val_loss: 0.5270 - val_accuracy: 0.7351 - val_auc: 0.8131\n",
      "Epoch 17/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.5016 - accuracy: 0.7479 - auc: 0.8308 - val_loss: 0.5364 - val_accuracy: 0.7191 - val_auc: 0.8058\n",
      "Epoch 18/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.4984 - accuracy: 0.7482 - auc: 0.8328 - val_loss: 0.5214 - val_accuracy: 0.7279 - val_auc: 0.8161\n",
      "Epoch 19/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.4988 - accuracy: 0.7487 - auc: 0.8335 - val_loss: 0.5213 - val_accuracy: 0.7365 - val_auc: 0.8175\n",
      "Epoch 20/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.4917 - accuracy: 0.7526 - auc: 0.8383 - val_loss: 0.5222 - val_accuracy: 0.7307 - val_auc: 0.8205\n",
      "Epoch 21/100\n",
      "763/763 [==============================] - 6s 7ms/step - loss: 0.4914 - accuracy: 0.7518 - auc: 0.8380 - val_loss: 0.5226 - val_accuracy: 0.7342 - val_auc: 0.8184\n",
      "Epoch 22/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.4886 - accuracy: 0.7532 - auc: 0.8406 - val_loss: 0.5175 - val_accuracy: 0.7302 - val_auc: 0.8214\n",
      "Epoch 23/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.4852 - accuracy: 0.7553 - auc: 0.8425 - val_loss: 0.5145 - val_accuracy: 0.7388 - val_auc: 0.8231\n",
      "Epoch 24/100\n",
      "763/763 [==============================] - 6s 7ms/step - loss: 0.4837 - accuracy: 0.7553 - auc: 0.8437 - val_loss: 0.5181 - val_accuracy: 0.7414 - val_auc: 0.8211\n",
      "Epoch 25/100\n",
      "763/763 [==============================] - 6s 7ms/step - loss: 0.4794 - accuracy: 0.7619 - auc: 0.8478 - val_loss: 0.5150 - val_accuracy: 0.7420 - val_auc: 0.8225\n",
      "Epoch 26/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.4791 - accuracy: 0.7581 - auc: 0.8466 - val_loss: 0.5201 - val_accuracy: 0.7369 - val_auc: 0.8257\n",
      "Epoch 27/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.4773 - accuracy: 0.7635 - auc: 0.8494 - val_loss: 0.5095 - val_accuracy: 0.7409 - val_auc: 0.8260\n",
      "Epoch 28/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.4744 - accuracy: 0.7603 - auc: 0.8505 - val_loss: 0.5086 - val_accuracy: 0.7379 - val_auc: 0.8276\n",
      "Epoch 29/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.4697 - accuracy: 0.7666 - auc: 0.8544 - val_loss: 0.5159 - val_accuracy: 0.7332 - val_auc: 0.8221\n",
      "Epoch 30/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.4705 - accuracy: 0.7641 - auc: 0.8537 - val_loss: 0.5064 - val_accuracy: 0.7404 - val_auc: 0.8298\n",
      "Epoch 31/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.4688 - accuracy: 0.7676 - auc: 0.8544 - val_loss: 0.5025 - val_accuracy: 0.7485 - val_auc: 0.8324\n",
      "Epoch 32/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.4631 - accuracy: 0.7696 - auc: 0.8581 - val_loss: 0.5096 - val_accuracy: 0.7467 - val_auc: 0.8336\n",
      "Epoch 33/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.4634 - accuracy: 0.7706 - auc: 0.8581 - val_loss: 0.4992 - val_accuracy: 0.7492 - val_auc: 0.8357\n",
      "Epoch 34/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.4602 - accuracy: 0.7720 - auc: 0.8597 - val_loss: 0.5089 - val_accuracy: 0.7397 - val_auc: 0.8309\n",
      "Epoch 35/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.4608 - accuracy: 0.7696 - auc: 0.8596 - val_loss: 0.5073 - val_accuracy: 0.7439 - val_auc: 0.8325\n",
      "Epoch 36/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.4555 - accuracy: 0.7748 - auc: 0.8628 - val_loss: 0.5041 - val_accuracy: 0.7379 - val_auc: 0.8301\n",
      "Epoch 37/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.4554 - accuracy: 0.7777 - auc: 0.8643 - val_loss: 0.5009 - val_accuracy: 0.7462 - val_auc: 0.8347\n",
      "Epoch 38/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.4482 - accuracy: 0.7803 - auc: 0.8679 - val_loss: 0.5079 - val_accuracy: 0.7400 - val_auc: 0.8328\n",
      "Epoch 39/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.4523 - accuracy: 0.7750 - auc: 0.8659 - val_loss: 0.4933 - val_accuracy: 0.7555 - val_auc: 0.8412\n",
      "Epoch 40/100\n",
      "763/763 [==============================] - 6s 7ms/step - loss: 0.4488 - accuracy: 0.7778 - auc: 0.8679 - val_loss: 0.4918 - val_accuracy: 0.7583 - val_auc: 0.8431\n",
      "Epoch 41/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.4449 - accuracy: 0.7810 - auc: 0.8703 - val_loss: 0.4990 - val_accuracy: 0.7497 - val_auc: 0.8412\n",
      "Epoch 42/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.4444 - accuracy: 0.7829 - auc: 0.8706 - val_loss: 0.4940 - val_accuracy: 0.7611 - val_auc: 0.8456\n",
      "Epoch 43/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.4407 - accuracy: 0.7852 - auc: 0.8732 - val_loss: 0.4918 - val_accuracy: 0.7534 - val_auc: 0.8435\n",
      "Epoch 44/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.4414 - accuracy: 0.7854 - auc: 0.8739 - val_loss: 0.4904 - val_accuracy: 0.7525 - val_auc: 0.8428\n",
      "Epoch 45/100\n",
      "763/763 [==============================] - 6s 7ms/step - loss: 0.4413 - accuracy: 0.7840 - auc: 0.8726 - val_loss: 0.4889 - val_accuracy: 0.7581 - val_auc: 0.8484\n",
      "Epoch 46/100\n",
      "763/763 [==============================] - 6s 8ms/step - loss: 0.4342 - accuracy: 0.7868 - auc: 0.8769 - val_loss: 0.5004 - val_accuracy: 0.7458 - val_auc: 0.8371\n",
      "Epoch 47/100\n",
      "763/763 [==============================] - 6s 7ms/step - loss: 0.4316 - accuracy: 0.7860 - auc: 0.8785 - val_loss: 0.4882 - val_accuracy: 0.7643 - val_auc: 0.8468\n",
      "Epoch 48/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.4285 - accuracy: 0.7891 - auc: 0.8799 - val_loss: 0.4834 - val_accuracy: 0.7678 - val_auc: 0.8525\n",
      "Epoch 49/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.4284 - accuracy: 0.7939 - auc: 0.8815 - val_loss: 0.4917 - val_accuracy: 0.7560 - val_auc: 0.8453\n",
      "Epoch 50/100\n",
      "763/763 [==============================] - 6s 7ms/step - loss: 0.4244 - accuracy: 0.7939 - auc: 0.8824 - val_loss: 0.4934 - val_accuracy: 0.7581 - val_auc: 0.8445\n",
      "Epoch 51/100\n",
      "763/763 [==============================] - 6s 7ms/step - loss: 0.4241 - accuracy: 0.7957 - auc: 0.8839 - val_loss: 0.4815 - val_accuracy: 0.7641 - val_auc: 0.8502\n",
      "Epoch 52/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.4212 - accuracy: 0.7975 - auc: 0.8849 - val_loss: 0.4823 - val_accuracy: 0.7685 - val_auc: 0.8537\n",
      "Epoch 53/100\n",
      "763/763 [==============================] - 6s 7ms/step - loss: 0.4241 - accuracy: 0.7932 - auc: 0.8828 - val_loss: 0.4856 - val_accuracy: 0.7678 - val_auc: 0.8509\n",
      "Epoch 54/100\n",
      "763/763 [==============================] - 6s 7ms/step - loss: 0.4193 - accuracy: 0.7955 - auc: 0.8861 - val_loss: 0.4886 - val_accuracy: 0.7588 - val_auc: 0.8502\n",
      "Epoch 55/100\n",
      "763/763 [==============================] - 6s 7ms/step - loss: 0.4234 - accuracy: 0.7970 - auc: 0.8854 - val_loss: 0.4822 - val_accuracy: 0.7687 - val_auc: 0.8549\n",
      "Epoch 56/100\n",
      "763/763 [==============================] - 6s 7ms/step - loss: 0.4159 - accuracy: 0.7988 - auc: 0.8877 - val_loss: 0.4727 - val_accuracy: 0.7729 - val_auc: 0.8584\n",
      "Epoch 57/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.4118 - accuracy: 0.8026 - auc: 0.8906 - val_loss: 0.4832 - val_accuracy: 0.7643 - val_auc: 0.8531\n",
      "Epoch 58/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.4101 - accuracy: 0.8014 - auc: 0.8912 - val_loss: 0.4768 - val_accuracy: 0.7678 - val_auc: 0.8579\n",
      "Epoch 59/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.4128 - accuracy: 0.8012 - auc: 0.8904 - val_loss: 0.4845 - val_accuracy: 0.7634 - val_auc: 0.8547\n",
      "Epoch 60/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.4074 - accuracy: 0.8067 - auc: 0.8932 - val_loss: 0.4756 - val_accuracy: 0.7697 - val_auc: 0.8582\n",
      "Epoch 61/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.4052 - accuracy: 0.8069 - auc: 0.8941 - val_loss: 0.4775 - val_accuracy: 0.7729 - val_auc: 0.8594\n",
      "Epoch 62/100\n",
      "763/763 [==============================] - 6s 7ms/step - loss: 0.4052 - accuracy: 0.8052 - auc: 0.8948 - val_loss: 0.4781 - val_accuracy: 0.7653 - val_auc: 0.8602\n",
      "Epoch 63/100\n",
      "763/763 [==============================] - 6s 7ms/step - loss: 0.4010 - accuracy: 0.8098 - auc: 0.8966 - val_loss: 0.4796 - val_accuracy: 0.7692 - val_auc: 0.8587\n",
      "Epoch 64/100\n",
      "763/763 [==============================] - 6s 7ms/step - loss: 0.3987 - accuracy: 0.8072 - auc: 0.8975 - val_loss: 0.4778 - val_accuracy: 0.7729 - val_auc: 0.8605\n",
      "Epoch 65/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.3973 - accuracy: 0.8093 - auc: 0.8980 - val_loss: 0.4857 - val_accuracy: 0.7674 - val_auc: 0.8595\n",
      "Epoch 66/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.3988 - accuracy: 0.8097 - auc: 0.8987 - val_loss: 0.4712 - val_accuracy: 0.7769 - val_auc: 0.8653\n",
      "Epoch 67/100\n",
      "763/763 [==============================] - 6s 7ms/step - loss: 0.3972 - accuracy: 0.8098 - auc: 0.8991 - val_loss: 0.4740 - val_accuracy: 0.7762 - val_auc: 0.8643\n",
      "Epoch 68/100\n",
      "763/763 [==============================] - 6s 7ms/step - loss: 0.3918 - accuracy: 0.8155 - auc: 0.9020 - val_loss: 0.4739 - val_accuracy: 0.7771 - val_auc: 0.8621\n",
      "Epoch 69/100\n",
      "763/763 [==============================] - 6s 7ms/step - loss: 0.3883 - accuracy: 0.8145 - auc: 0.9036 - val_loss: 0.4854 - val_accuracy: 0.7764 - val_auc: 0.8624\n",
      "Epoch 70/100\n",
      "763/763 [==============================] - 6s 7ms/step - loss: 0.3872 - accuracy: 0.8185 - auc: 0.9039 - val_loss: 0.4769 - val_accuracy: 0.7706 - val_auc: 0.8644\n",
      "Epoch 71/100\n",
      "763/763 [==============================] - 6s 8ms/step - loss: 0.3862 - accuracy: 0.8171 - auc: 0.9048 - val_loss: 0.4698 - val_accuracy: 0.7808 - val_auc: 0.8700\n",
      "Epoch 72/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.3835 - accuracy: 0.8189 - auc: 0.9059 - val_loss: 0.4668 - val_accuracy: 0.7855 - val_auc: 0.8689\n",
      "Epoch 73/100\n",
      "763/763 [==============================] - 6s 8ms/step - loss: 0.3873 - accuracy: 0.8160 - auc: 0.9047 - val_loss: 0.4708 - val_accuracy: 0.7764 - val_auc: 0.8663\n",
      "Epoch 74/100\n",
      "763/763 [==============================] - 6s 8ms/step - loss: 0.3783 - accuracy: 0.8190 - auc: 0.9086 - val_loss: 0.4748 - val_accuracy: 0.7752 - val_auc: 0.8653\n",
      "Epoch 75/100\n",
      "763/763 [==============================] - 6s 7ms/step - loss: 0.3825 - accuracy: 0.8221 - auc: 0.9076 - val_loss: 0.4706 - val_accuracy: 0.7785 - val_auc: 0.8687\n",
      "Epoch 76/100\n",
      "763/763 [==============================] - 6s 7ms/step - loss: 0.3772 - accuracy: 0.8233 - auc: 0.9098 - val_loss: 0.4822 - val_accuracy: 0.7715 - val_auc: 0.8654\n",
      "Epoch 77/100\n",
      "763/763 [==============================] - 6s 8ms/step - loss: 0.3788 - accuracy: 0.8194 - auc: 0.9081 - val_loss: 0.4706 - val_accuracy: 0.7813 - val_auc: 0.8680\n",
      "Epoch 78/100\n",
      "763/763 [==============================] - 6s 7ms/step - loss: 0.3728 - accuracy: 0.8221 - auc: 0.9116 - val_loss: 0.4578 - val_accuracy: 0.7901 - val_auc: 0.8748\n",
      "Epoch 79/100\n",
      "763/763 [==============================] - 6s 8ms/step - loss: 0.3706 - accuracy: 0.8267 - auc: 0.9124 - val_loss: 0.4669 - val_accuracy: 0.7831 - val_auc: 0.8705\n",
      "Epoch 80/100\n",
      "763/763 [==============================] - 6s 7ms/step - loss: 0.3734 - accuracy: 0.8231 - auc: 0.9118 - val_loss: 0.4807 - val_accuracy: 0.7778 - val_auc: 0.8669\n",
      "Epoch 81/100\n",
      "763/763 [==============================] - 6s 7ms/step - loss: 0.3675 - accuracy: 0.8266 - auc: 0.9139 - val_loss: 0.4651 - val_accuracy: 0.7864 - val_auc: 0.8756\n",
      "Epoch 82/100\n",
      "763/763 [==============================] - 6s 8ms/step - loss: 0.3639 - accuracy: 0.8305 - auc: 0.9162 - val_loss: 0.4606 - val_accuracy: 0.7901 - val_auc: 0.8748\n",
      "Epoch 83/100\n",
      "763/763 [==============================] - 6s 7ms/step - loss: 0.3612 - accuracy: 0.8291 - auc: 0.9169 - val_loss: 0.4799 - val_accuracy: 0.7827 - val_auc: 0.8673\n",
      "Epoch 84/100\n",
      "763/763 [==============================] - 6s 7ms/step - loss: 0.3601 - accuracy: 0.8314 - auc: 0.9179 - val_loss: 0.4581 - val_accuracy: 0.7899 - val_auc: 0.8777\n",
      "Epoch 85/100\n",
      "763/763 [==============================] - 6s 8ms/step - loss: 0.3680 - accuracy: 0.8266 - auc: 0.9148 - val_loss: 0.4678 - val_accuracy: 0.7780 - val_auc: 0.8722\n",
      "Epoch 86/100\n",
      "763/763 [==============================] - 6s 7ms/step - loss: 0.3584 - accuracy: 0.8326 - auc: 0.9194 - val_loss: 0.4719 - val_accuracy: 0.7857 - val_auc: 0.8734\n",
      "Epoch 87/100\n",
      "763/763 [==============================] - 6s 7ms/step - loss: 0.3621 - accuracy: 0.8284 - auc: 0.9173 - val_loss: 0.4539 - val_accuracy: 0.7920 - val_auc: 0.8782\n",
      "Epoch 88/100\n",
      "763/763 [==============================] - 6s 7ms/step - loss: 0.3559 - accuracy: 0.8335 - auc: 0.9199 - val_loss: 0.4760 - val_accuracy: 0.7836 - val_auc: 0.8751\n",
      "Epoch 89/100\n",
      "763/763 [==============================] - 6s 8ms/step - loss: 0.3545 - accuracy: 0.8360 - auc: 0.9206 - val_loss: 0.4618 - val_accuracy: 0.7903 - val_auc: 0.8807\n",
      "Epoch 90/100\n",
      "763/763 [==============================] - 6s 7ms/step - loss: 0.3529 - accuracy: 0.8358 - auc: 0.9208 - val_loss: 0.4538 - val_accuracy: 0.7975 - val_auc: 0.8815\n",
      "Epoch 91/100\n",
      "763/763 [==============================] - 6s 8ms/step - loss: 0.3539 - accuracy: 0.8356 - auc: 0.9212 - val_loss: 0.4622 - val_accuracy: 0.7950 - val_auc: 0.8791\n",
      "Epoch 92/100\n",
      "763/763 [==============================] - 6s 7ms/step - loss: 0.3496 - accuracy: 0.8369 - auc: 0.9225 - val_loss: 0.4540 - val_accuracy: 0.7941 - val_auc: 0.8819\n",
      "Epoch 93/100\n",
      "763/763 [==============================] - 6s 7ms/step - loss: 0.3479 - accuracy: 0.8398 - auc: 0.9238 - val_loss: 0.4695 - val_accuracy: 0.7929 - val_auc: 0.8828\n",
      "Epoch 94/100\n",
      "763/763 [==============================] - 6s 7ms/step - loss: 0.3484 - accuracy: 0.8402 - auc: 0.9240 - val_loss: 0.4701 - val_accuracy: 0.7945 - val_auc: 0.8786\n",
      "Epoch 95/100\n",
      "763/763 [==============================] - 5s 7ms/step - loss: 0.3486 - accuracy: 0.8386 - auc: 0.9239 - val_loss: 0.4631 - val_accuracy: 0.7992 - val_auc: 0.8818\n",
      "Epoch 96/100\n",
      "763/763 [==============================] - 6s 7ms/step - loss: 0.3447 - accuracy: 0.8417 - auc: 0.9255 - val_loss: 0.4563 - val_accuracy: 0.8071 - val_auc: 0.8849\n",
      "Epoch 97/100\n",
      "763/763 [==============================] - 6s 7ms/step - loss: 0.3456 - accuracy: 0.8396 - auc: 0.9251 - val_loss: 0.4738 - val_accuracy: 0.7952 - val_auc: 0.8784\n",
      "Epoch 98/100\n",
      "763/763 [==============================] - 6s 7ms/step - loss: 0.3431 - accuracy: 0.8419 - auc: 0.9260 - val_loss: 0.4649 - val_accuracy: 0.7996 - val_auc: 0.8835\n",
      "Epoch 99/100\n",
      "763/763 [==============================] - 6s 8ms/step - loss: 0.3425 - accuracy: 0.8460 - auc: 0.9270 - val_loss: 0.4635 - val_accuracy: 0.7992 - val_auc: 0.8817\n",
      "Epoch 100/100\n",
      "763/763 [==============================] - 6s 7ms/step - loss: 0.3408 - accuracy: 0.8413 - auc: 0.9269 - val_loss: 0.4606 - val_accuracy: 0.7980 - val_auc: 0.8821\n",
      "135/135 [==============================] - 0s 2ms/step\n",
      "ROC-AUC: 0.8820915848790494\n",
      "Accuracy: 0.7980032505224054\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, LSTM, Dropout, Input, concatenate\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "# First branch for the LSTM\n",
    "lstm_input = Input(shape=(1, 100))\n",
    "lstm_output = LSTM(units=256, return_sequences=True, activation='relu')(lstm_input)\n",
    "lstm_output = Dropout(0.2)(lstm_output)\n",
    "lstm_output = LSTM(units=128, activation='relu')(lstm_output)\n",
    "lstm_output = Dropout(0.2)(lstm_output)\n",
    "\n",
    "# Second branch for the dense layers\n",
    "dense_input = Input(shape=(5,))\n",
    "dense_output = Dense(units=64, activation='relu')(dense_input)\n",
    "dense_output = Dropout(0.2)(dense_output)\n",
    "\n",
    "# Concatenate the outputs from both branches\n",
    "combined = concatenate([lstm_output, dense_output])\n",
    "\n",
    "combined = Dense(units = 64, activation='relu')(combined)\n",
    "\n",
    "# Final output layer\n",
    "output = Dense(units=1, activation='sigmoid')(combined)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=[lstm_input, dense_input], outputs=output)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', 'AUC'])\n",
    "\n",
    "# Define the early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model with both LSTM and dense input\n",
    "model.fit([X_train_vec, X_train], y_train, epochs=100, batch_size=32,\n",
    "          validation_data=([X_test_vec, X_test], y_test),\n",
    "          callbacks=[early_stopping])\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict([X_test_vec, X_test])\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "y_pred_class = (y_pred > .5).astype(int)\n",
    "accuracy = accuracy_score(y_test,y_pred_class)\n",
    "print('ROC-AUC:', roc_auc)\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "matrix = confusion_matrix(y_test, y_pred_class)\n",
    "\n",
    "sns.heatmap(matrix/np.sum(matrix), annot=True, fmt='.2%', cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59dc53ff-9c21-466a-8e9f-f10b3833b0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model containing character length, number of capital words, upvotes and # of comments\n",
    "#Model 2 adds POS tagging and standard scaling of variables\n",
    "#Only left in proper nouns as others decreased performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77a3b55f-1112-4739-b2cf-337ce0205e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "#create extra variables for later\n",
    "df_other_var = create_other_var(df)\n",
    "\n",
    "#Create simple dataframe with only text and predictor\n",
    "df = df[['Title','Political Lean']] \n",
    "\n",
    "#dummy code predictor\n",
    "df['Political Lean'] = df['Political Lean'].replace('Liberal',1)\n",
    "df['Political Lean'] = df['Political Lean'].replace('Conservative',0)\n",
    "\n",
    "df = df.rename({'Political Lean':'y'},axis=1) #replace column name for simplicity\n",
    "\n",
    "df = pd.concat([df,df_other_var],axis=1)\n",
    "\n",
    "df = df[df['Length']>=15]\n",
    "\n",
    "#Split into X & y\n",
    "X = df.drop(['y'],axis=1)\n",
    "y = df['y']\n",
    "\n",
    "#oversample minority class\n",
    "oversample = RandomOverSampler(sampling_strategy='minority', random_state=13)\n",
    "X, y = oversample.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eed9495c-923f-474f-9f74-dd19b9ac4074",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'merge'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m loss_df \u001b[38;5;241m=\u001b[39m \u001b[43mX_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m(X[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTitle\u001b[39m\u001b[38;5;124m'\u001b[39m]],left_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,right_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m loss_df \u001b[38;5;241m=\u001b[39m loss_df\u001b[38;5;241m.\u001b[39mmerge(y,left_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,right_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m predictions \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(y_pred, columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprob\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'merge'"
     ]
    }
   ],
   "source": [
    "loss_df = X_test.merge(X[['Title']],left_index=True,right_index=True,how='left')\n",
    "loss_df = loss_df.merge(y,left_index=True,right_index=True,how='left')\n",
    "predictions = pd.DataFrame(y_pred, columns = ['prob'])\n",
    "loss_df = pd.concat([loss_df,predictions.set_index(loss_df.index)],axis=1)\n",
    "loss_df['prob'] = abs(loss_df['prob']-.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83928af4-ce6f-427f-89a2-874bc4d50d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_df.sort_values(by='prob').head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ea316a-dd0e-403b-941b-a187813ce181",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LHL_env",
   "language": "python",
   "name": "lhl_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
